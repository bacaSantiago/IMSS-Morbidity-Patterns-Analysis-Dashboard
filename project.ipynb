{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historia de nuestros datos\n",
    "\n",
    "De donde se obtuvieron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\n\\ncovid_cierre_2023 = pd.read_csv(\\'COVID19MEXICO2023.csv\\')\\ncovid_cierre_2022 = pd.read_csv(\\'COVID19MEXICO2022.csv\\')\\ncovid_cierre_2021 = pd.read_csv(\\'COVID19MEXICO2021.csv\\')\\ncovid_cierre_2020 = pd.read_csv(\\'COVID19MEXICO2020.csv\\')\\n\\n# Check if all column sets are identical\\ncolumns_match = (covid_cierre_2023.columns == covid_cierre_2022.columns).all() and                 (covid_cierre_2022.columns == covid_cierre_2021.columns).all() and                 (covid_cierre_2021.columns == covid_cierre_2020.columns).all()\\n\\nif columns_match:\\n    print(\"All DataFrames have identical columns.\")\\n    # Concatenate all DataFrames\\n    covid_cierre = pd.concat([covid_cierre_2022, covid_cierre_2023, covid_cierre_2021, covid_cierre_2020])\\n    covid_cierre.to_csv(\\'COVID19MEXICO.csv\\', index=False)\\nelse:\\n    # Calculate and print mismatches if columns differ\\n    mismatch_count = sum(covid_cierre_2023.columns != covid_cierre_2022.columns) +                      sum(covid_cierre_2022.columns != covid_cierre_2021.columns) +                      sum(covid_cierre_2021.columns != covid_cierre_2020.columns)\\n    print(\"Number of mismatched columns:\", mismatch_count)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "covid_cierre_2023 = pd.read_csv('COVID19MEXICO2023.csv')\n",
    "covid_cierre_2022 = pd.read_csv('COVID19MEXICO2022.csv')\n",
    "covid_cierre_2021 = pd.read_csv('COVID19MEXICO2021.csv')\n",
    "covid_cierre_2020 = pd.read_csv('COVID19MEXICO2020.csv')\n",
    "\n",
    "# Check if all column sets are identical\n",
    "columns_match = (covid_cierre_2023.columns == covid_cierre_2022.columns).all() and \\\n",
    "                (covid_cierre_2022.columns == covid_cierre_2021.columns).all() and \\\n",
    "                (covid_cierre_2021.columns == covid_cierre_2020.columns).all()\n",
    "\n",
    "if columns_match:\n",
    "    print(\"All DataFrames have identical columns.\")\n",
    "    # Concatenate all DataFrames\n",
    "    covid_cierre = pd.concat([covid_cierre_2022, covid_cierre_2023, covid_cierre_2021, covid_cierre_2020])\n",
    "    covid_cierre.to_csv('COVID19MEXICO.csv', index=False)\n",
    "else:\n",
    "    # Calculate and print mismatches if columns differ\n",
    "    mismatch_count = sum(covid_cierre_2023.columns != covid_cierre_2022.columns) + \\\n",
    "                     sum(covid_cierre_2022.columns != covid_cierre_2021.columns) + \\\n",
    "                     sum(covid_cierre_2021.columns != covid_cierre_2020.columns)\n",
    "    print(\"Number of mismatched columns:\", mismatch_count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/hxfkbjc14h9d9m0ch12z7qh00000gn/T/ipykernel_802/1616677954.py:3: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  covid_df = pd.read_csv('COVID19MEXICO.csv')\n"
     ]
    }
   ],
   "source": [
    "# Upload the file \n",
    "import pandas as pd\n",
    "covid_df = pd.read_csv('COVID19MEXICO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Data Type  Unique Values\n",
      "FECHA_ACTUALIZACION      object              4\n",
      "ID_REGISTRO              object       20455477\n",
      "ORIGEN                    int64              2\n",
      "SECTOR                    int64             16\n",
      "ENTIDAD_UM                int64             32\n",
      "SEXO                      int64              2\n",
      "ENTIDAD_NAC               int64             33\n",
      "ENTIDAD_RES               int64             32\n",
      "MUNICIPIO_RES             int64            569\n",
      "TIPO_PACIENTE             int64              2\n",
      "FECHA_INGRESO            object           1598\n",
      "FECHA_SINTOMAS           object           1598\n",
      "FECHA_DEF                object           1597\n",
      "INTUBADO                  int64              4\n",
      "NEUMONIA                  int64              3\n",
      "EDAD                      int64            143\n",
      "NACIONALIDAD              int64              2\n",
      "EMBARAZO                  int64              5\n",
      "HABLA_LENGUA_INDIG        int64              3\n",
      "INDIGENA                  int64              3\n",
      "DIABETES                  int64              3\n",
      "EPOC                      int64              3\n",
      "ASMA                      int64              3\n",
      "INMUSUPR                  int64              3\n",
      "HIPERTENSION              int64              3\n",
      "OTRA_COM                  int64              3\n",
      "CARDIOVASCULAR            int64              3\n",
      "OBESIDAD                  int64              3\n",
      "RENAL_CRONICA             int64              3\n",
      "TABAQUISMO                int64              3\n",
      "OTRO_CASO                 int64              3\n",
      "TOMA_MUESTRA_LAB          int64              2\n",
      "RESULTADO_LAB             int64              5\n",
      "TOMA_MUESTRA_ANTIGENO     int64              2\n",
      "RESULTADO_ANTIGENO        int64              3\n",
      "CLASIFICACION_FINAL       int64              7\n",
      "MIGRANTE                  int64              3\n",
      "PAIS_NACIONALIDAD        object            205\n",
      "PAIS_ORIGEN              object            152\n",
      "UCI                       int64              4\n"
     ]
    }
   ],
   "source": [
    "# Show the type of data in each column and all the possible unique values, store it in a dataframe\n",
    "data_types = pd.DataFrame(covid_df.dtypes, columns=['Data Type'])\n",
    "unique_values = pd.DataFrame(covid_df.nunique(), columns=['Unique Values'])\n",
    "data_types = data_types.join(unique_values)\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# See if there are any missing values\n",
    "print('Missing values:', covid_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# See if there are any duplicated rows\n",
    "print('Duplicated rows:', covid_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20455481, 40)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>ORIGEN</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>ENTIDAD_UM</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>ENTIDAD_NAC</th>\n",
       "      <th>ENTIDAD_RES</th>\n",
       "      <th>MUNICIPIO_RES</th>\n",
       "      <th>TIPO_PACIENTE</th>\n",
       "      <th>...</th>\n",
       "      <th>OTRO_CASO</th>\n",
       "      <th>TOMA_MUESTRA_LAB</th>\n",
       "      <th>RESULTADO_LAB</th>\n",
       "      <th>TOMA_MUESTRA_ANTIGENO</th>\n",
       "      <th>RESULTADO_ANTIGENO</th>\n",
       "      <th>CLASIFICACION_FINAL</th>\n",
       "      <th>MIGRANTE</th>\n",
       "      <th>PAIS_NACIONALIDAD</th>\n",
       "      <th>PAIS_ORIGEN</th>\n",
       "      <th>UCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14791593</th>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>67dd8f</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216180</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>67dd8f</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557715</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>8142bf</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16413207</th>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>8142bf</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972560</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>a49952</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16332937</th>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>a49952</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556760</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>g1feb61</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464820</th>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>g1feb61</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>México</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FECHA_ACTUALIZACION ID_REGISTRO  ORIGEN  SECTOR  ENTIDAD_UM  SEXO  \\\n",
       "14791593          2022-08-09      67dd8f       1       6          10     2   \n",
       "20216180          2021-10-31      67dd8f       1       6          10     2   \n",
       "5557715           2023-06-01      8142bf       2       4          23     1   \n",
       "16413207          2022-08-09      8142bf       2       4          23     1   \n",
       "4972560           2023-06-01      a49952       2       4          12     2   \n",
       "16332937          2022-08-09      a49952       2       4          12     2   \n",
       "3556760           2023-06-01     g1feb61       1       8          27     2   \n",
       "16464820          2022-08-09     g1feb61       1       8          27     2   \n",
       "\n",
       "          ENTIDAD_NAC  ENTIDAD_RES  MUNICIPIO_RES  TIPO_PACIENTE  ...  \\\n",
       "14791593           10           10              5              1  ...   \n",
       "20216180           10           10              5              1  ...   \n",
       "5557715            31           23              1              2  ...   \n",
       "16413207           31           23              1              2  ...   \n",
       "4972560            12           12              1              1  ...   \n",
       "16332937           12           12              1              1  ...   \n",
       "3556760            27           27              4              1  ...   \n",
       "16464820           27           27              4              1  ...   \n",
       "\n",
       "         OTRO_CASO TOMA_MUESTRA_LAB RESULTADO_LAB  TOMA_MUESTRA_ANTIGENO  \\\n",
       "14791593        99                1             2                      2   \n",
       "20216180        99                1             2                      2   \n",
       "5557715          2                2            97                      1   \n",
       "16413207         2                2            97                      2   \n",
       "4972560          2                2            97                      2   \n",
       "16332937         2                2            97                      1   \n",
       "3556760         99                2            97                      1   \n",
       "16464820        99                2            97                      1   \n",
       "\n",
       "          RESULTADO_ANTIGENO  CLASIFICACION_FINAL  MIGRANTE  \\\n",
       "14791593                  97                    7        99   \n",
       "20216180                  97                    7        99   \n",
       "5557715                    1                    3        99   \n",
       "16413207                  97                    6        99   \n",
       "4972560                   97                    6        99   \n",
       "16332937                   1                    3        99   \n",
       "3556760                    1                    3        99   \n",
       "16464820                   1                    3        99   \n",
       "\n",
       "          PAIS_NACIONALIDAD  PAIS_ORIGEN  UCI  \n",
       "14791593             México           97   97  \n",
       "20216180             México           97   97  \n",
       "5557715              México           97    2  \n",
       "16413207             México           97    2  \n",
       "4972560              México           97   97  \n",
       "16332937             México           97   97  \n",
       "3556760              México           97   97  \n",
       "16464820             México           97   97  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names\n",
    "column_names = covid_df.columns\n",
    "\n",
    "# Get the repeated 'ID_REGISTRO' indexes and print those rows\n",
    "repeated_IDS = covid_df[covid_df.duplicated(subset='ID_REGISTRO', keep=False)].sort_values('ID_REGISTRO')\n",
    "repeated_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20455473, 40)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the repeated rows from 'repeated_IDS'\n",
    "covid_df = covid_df.drop(repeated_IDS.index)\n",
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01\n",
      "2024-05-16\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest 'FECHA_INGRESO' dates\n",
    "print(covid_df['FECHA_INGRESO'].min())\n",
    "print(covid_df['FECHA_INGRESO'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La vigilancia centinela se realiza a través del sistema de unidades de salud monitoras de enfermedades respiratorias (USMER). Las USMER incluyen unidades médicas del primer, segundo o tercer nivel de atención y también participan como USMER las unidades de tercer nivel que por sus características contribuyen a ampliar el panorama de información epidemiológica, entre ellas las que cuenten con especialidad de neumología, infectología o pediatría. \n",
    "\n",
    "ORIGEN:\n",
    "\n",
    "- 1 : USMER\n",
    "- 2 : FUERA DE USMER\n",
    "- 99 : NO ESPECIFICADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20455473 entries, 0 to 20455480\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   FECHA_ACTUALIZACION  datetime64[ns]\n",
      " 1   FECHA_INGRESO        datetime64[ns]\n",
      " 2   FECHA_SINTOMAS       datetime64[ns]\n",
      " 3   FECHA_DEF            datetime64[ns]\n",
      "dtypes: datetime64[ns](4)\n",
      "memory usage: 780.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace invalid date entries with NaN and convert to datetime\n",
    "date_columns = ['FECHA_ACTUALIZACION', 'FECHA_INGRESO', 'FECHA_SINTOMAS', 'FECHA_DEF']\n",
    "for col in date_columns:\n",
    "    covid_df[col] = covid_df[col].replace(['9999-99-99'] , pd.NaT)\n",
    "    covid_df[col] = pd.to_datetime(covid_df[col], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "# Check if dates were successfully converted\n",
    "print(covid_df[date_columns].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00\n",
      "2024-05-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest 'FECHA_INGRESO' dates\n",
    "print(covid_df['FECHA_INGRESO'].min())\n",
    "print(covid_df['FECHA_INGRESO'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20450790, 40)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unreasable ages\n",
    "covid_df = covid_df.drop(covid_df[(covid_df['EDAD'] < 0) | (covid_df['EDAD'] >= 120)][['EDAD']].index) # Approx 5k rows\n",
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.to_csv('Clean_COVID19MEXICO.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entidades_df = pd.read_csv('Catalogos/ENTIDADES.csv')\n",
    "#municipios_df = pd.read_csv('Catalogos/MUNICIPIOS.csv')\n",
    "#nacionalidad_df = pd.read_csv('Catalogos/NACIONALIDAD.csv')\n",
    "#resultados_df = pd.read_csv('Catalogos/RESULTADO.csv')\n",
    "#sectores_df = pd.read_csv('Catalogos/SECTOR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Febriles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames have identical columns.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "febriles_2024 = pd.read_csv('FEBRILES/Febriles_2024.csv')\n",
    "febriles_2023 = pd.read_csv('FEBRILES/Febriles_2023.csv')\n",
    "febriles_2022 = pd.read_csv('FEBRILES/Febriles_2022.csv')\n",
    "febriles_2021 = pd.read_csv('FEBRILES/Febriles_2021.csv')\n",
    "febriles_2020 = pd.read_csv('FEBRILES/Febriles_2020.csv')\n",
    "\n",
    "# Check if all column sets are identical\n",
    "columns_match = (febriles_2024.columns == febriles_2023.columns).all() and \\\n",
    "                (febriles_2023.columns == febriles_2022.columns).all() and \\\n",
    "                (febriles_2022.columns == febriles_2021.columns).all() and \\\n",
    "                (febriles_2021.columns == febriles_2020.columns).all()\n",
    "\n",
    "if columns_match:\n",
    "    print(\"All DataFrames have identical columns.\")\n",
    "    # Concatenate all DataFrames\n",
    "    febriles = pd.concat([febriles_2024, febriles_2023, febriles_2022, febriles_2021, febriles_2020])\n",
    "    febriles.to_csv('Febriles.csv', index=False)\n",
    "else:\n",
    "    # Calculate and print mismatches if columns differ\n",
    "    mismatch_count = sum(febriles_2024.columns != febriles_2023.columns) + \\\n",
    "                     sum(febriles_2023.columns != febriles_2022.columns) + \\\n",
    "                     sum(febriles_2022.columns != febriles_2021.columns) + \\\n",
    "                     sum(febriles_2021.columns != febriles_2020.columns)\n",
    "    print(\"Number of mismatched columns:\", mismatch_count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>EDAD_ANOS</th>\n",
       "      <th>EDAD_MESES</th>\n",
       "      <th>EDAD_DIAS</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>HABLA_LENGUA_INDIG</th>\n",
       "      <th>INDIGENA</th>\n",
       "      <th>ENTIDAD_UM_NOTIF</th>\n",
       "      <th>MUNICIPIO_UM_NOTIF</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTITUCION_NOTIF</th>\n",
       "      <th>VACUNACION</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>FIEBRE</th>\n",
       "      <th>COMPLICACIONES</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>DIAGNOSTICO</th>\n",
       "      <th>CRITERIO_DIAGNOSTICO</th>\n",
       "      <th>FECHA_DIAGNOSTICO</th>\n",
       "      <th>ORIGEN_CASO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19/11/2024</td>\n",
       "      <td>27101</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>08/01/2024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19/11/2024</td>\n",
       "      <td>27102</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27/02/2024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19/11/2024</td>\n",
       "      <td>27103</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>08/03/2024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19/11/2024</td>\n",
       "      <td>27104</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01/2024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19/11/2024</td>\n",
       "      <td>27105</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22/03/2024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA_ACTUALIZACION  ID_REGISTRO  EDAD_ANOS  EDAD_MESES  EDAD_DIAS  SEXO  \\\n",
       "0          19/11/2024        27101          8           9          8     1   \n",
       "1          19/11/2024        27102          1           8         29     2   \n",
       "2          19/11/2024        27103         28           6         29     1   \n",
       "3          19/11/2024        27104         10           3          3     2   \n",
       "4          19/11/2024        27105          1           4         12     1   \n",
       "\n",
       "   HABLA_LENGUA_INDIG  INDIGENA  ENTIDAD_UM_NOTIF  MUNICIPIO_UM_NOTIF  ...  \\\n",
       "0                   2         2                12                  29  ...   \n",
       "1                   2         2                14                 101  ...   \n",
       "2                   2         2                30                 141  ...   \n",
       "3                   2         2                27                   6  ...   \n",
       "4                   2         2                28                  17  ...   \n",
       "\n",
       "   INSTITUCION_NOTIF  VACUNACION  EXANTEMA  FIEBRE  COMPLICACIONES  DEFUNCION  \\\n",
       "0                 12           2         1     1.0               2          2   \n",
       "1                 12           2         1     1.0               2          2   \n",
       "2                  4           1         1     1.0               2          2   \n",
       "3                 20           1         1     1.0               2          2   \n",
       "4                  5           1         1     1.0               2          2   \n",
       "\n",
       "   DIAGNOSTICO  CRITERIO_DIAGNOSTICO  FECHA_DIAGNOSTICO  ORIGEN_CASO  \n",
       "0            3                     2         08/01/2024          5.0  \n",
       "1            3                     1         27/02/2024          5.0  \n",
       "2            3                     2         08/03/2024          5.0  \n",
       "3            3                     2         12/01/2024          5.0  \n",
       "4            3                     1         22/03/2024          5.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enfermedades Febriles Exantemáticas\n",
    "febriles_df = pd.read_csv('Febriles.csv')\n",
    "febriles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11652 entries, 0 to 11651\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   FECHA_ACTUALIZACION   11652 non-null  object \n",
      " 1   ID_REGISTRO           11652 non-null  int64  \n",
      " 2   EDAD_ANOS             11652 non-null  int64  \n",
      " 3   EDAD_MESES            11652 non-null  int64  \n",
      " 4   EDAD_DIAS             11652 non-null  int64  \n",
      " 5   SEXO                  11652 non-null  int64  \n",
      " 6   HABLA_LENGUA_INDIG    11652 non-null  int64  \n",
      " 7   INDIGENA              11652 non-null  int64  \n",
      " 8   ENTIDAD_UM_NOTIF      11652 non-null  int64  \n",
      " 9   MUNICIPIO_UM_NOTIF    11652 non-null  int64  \n",
      " 10  ENTIDAD_RES           11652 non-null  int64  \n",
      " 11  MUNICIPIO_RES         11652 non-null  int64  \n",
      " 12  INSTITUCION_NOTIF     11652 non-null  int64  \n",
      " 13  VACUNACION            11652 non-null  int64  \n",
      " 14  EXANTEMA              11652 non-null  int64  \n",
      " 15  FIEBRE                11651 non-null  float64\n",
      " 16  COMPLICACIONES        11652 non-null  int64  \n",
      " 17  DEFUNCION             11652 non-null  int64  \n",
      " 18  DIAGNOSTICO           11652 non-null  int64  \n",
      " 19  CRITERIO_DIAGNOSTICO  11652 non-null  int64  \n",
      " 20  FECHA_DIAGNOSTICO     11652 non-null  object \n",
      " 21  ORIGEN_CASO           11649 non-null  float64\n",
      "dtypes: float64(2), int64(18), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "febriles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/02/2024\n",
      "9999-99-99\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest 'FECHA_DIAGNOSTICO' dates\n",
    "print(febriles_df['FECHA_DIAGNOSTICO'].min())\n",
    "print(febriles_df['FECHA_DIAGNOSTICO'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 4\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# See if there are any missing values and duplicated rows\n",
    "print('Missing values:', febriles_df.isnull().sum().sum())\n",
    "print('Duplicated rows:', febriles_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "febriles_df = febriles_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeated IDs\n"
     ]
    }
   ],
   "source": [
    "# Get the repeated 'ID_REGISTRO' indexes and print those rows\n",
    "repeated_IDS = febriles_df[febriles_df.duplicated(subset='ID_REGISTRO', keep=False)].sort_values('ID_REGISTRO')\n",
    "print(repeated_IDS if not repeated_IDS.empty else 'No repeated IDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['19/11/2024', '2023-12-04', '2022-11-29', '2021-12-14',\n",
       "       '2020-12-23'], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "febriles_df['FECHA_ACTUALIZACION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11648 entries, 0 to 11651\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   FECHA_ACTUALIZACION  11648 non-null  datetime64[ns]\n",
      " 1   FECHA_DIAGNOSTICO    10797 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2)\n",
      "memory usage: 273.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace invalid date entries with NaT and convert to datetime\n",
    "for col in ['FECHA_ACTUALIZACION', 'FECHA_DIAGNOSTICO']:\n",
    "    febriles_df[col] = febriles_df[col].replace(['9999-99-99'], pd.NaT)\n",
    "    febriles_df[col] = febriles_df[col].astype(str).apply(\n",
    "        lambda x: pd.to_datetime(x, format='%d/%m/%Y', errors='coerce', dayfirst=True) if x.endswith('2024') else pd.to_datetime(x, errors='coerce', format='%Y-%m-%d')\n",
    "    )\n",
    "\n",
    "# Check if dates were succesfully converted\n",
    "print(febriles_df[['FECHA_ACTUALIZACION', 'FECHA_DIAGNOSTICO']].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965-11-06 00:00:00\n",
      "2024-11-18 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest 'FECHA_DIAGNOSTICO' dates\n",
    "print(febriles_df['FECHA_DIAGNOSTICO'].min())\n",
    "print(febriles_df['FECHA_DIAGNOSTICO'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>EDAD_ANOS</th>\n",
       "      <th>EDAD_MESES</th>\n",
       "      <th>EDAD_DIAS</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>HABLA_LENGUA_INDIG</th>\n",
       "      <th>INDIGENA</th>\n",
       "      <th>ENTIDAD_UM_NOTIF</th>\n",
       "      <th>MUNICIPIO_UM_NOTIF</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTITUCION_NOTIF</th>\n",
       "      <th>VACUNACION</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>FIEBRE</th>\n",
       "      <th>COMPLICACIONES</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>DIAGNOSTICO</th>\n",
       "      <th>CRITERIO_DIAGNOSTICO</th>\n",
       "      <th>FECHA_DIAGNOSTICO</th>\n",
       "      <th>ORIGEN_CASO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>24052</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1965-11-06</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>24054</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1965-11-08</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FECHA_ACTUALIZACION  ID_REGISTRO  EDAD_ANOS  EDAD_MESES  EDAD_DIAS  SEXO  \\\n",
       "7159          2022-11-29        24052          2           6         23     2   \n",
       "7161          2022-11-29        24054         13           5         11     2   \n",
       "\n",
       "      HABLA_LENGUA_INDIG  INDIGENA  ENTIDAD_UM_NOTIF  MUNICIPIO_UM_NOTIF  ...  \\\n",
       "7159                   2         2                30                  87  ...   \n",
       "7161                   2         2                11                  37  ...   \n",
       "\n",
       "      INSTITUCION_NOTIF  VACUNACION  EXANTEMA  FIEBRE  COMPLICACIONES  \\\n",
       "7159                  4           1         1     1.0               2   \n",
       "7161                 12           1         1     1.0               2   \n",
       "\n",
       "      DEFUNCION  DIAGNOSTICO  CRITERIO_DIAGNOSTICO  FECHA_DIAGNOSTICO  \\\n",
       "7159          2            3                     0         1965-11-06   \n",
       "7161          2            3                     0         1965-11-08   \n",
       "\n",
       "      ORIGEN_CASO  \n",
       "7159          5.0  \n",
       "7161          5.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dates less than 2020\n",
    "febriles_df[febriles_df['FECHA_DIAGNOSTICO'] < '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with 'FECHA_DIAGNOSTICO' less than 2020\n",
    "febriles_df = febriles_df[febriles_df['FECHA_DIAGNOSTICO'] >= '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>EDAD_ANOS</th>\n",
       "      <th>EDAD_MESES</th>\n",
       "      <th>EDAD_DIAS</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>HABLA_LENGUA_INDIG</th>\n",
       "      <th>INDIGENA</th>\n",
       "      <th>ENTIDAD_UM_NOTIF</th>\n",
       "      <th>MUNICIPIO_UM_NOTIF</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTITUCION_NOTIF</th>\n",
       "      <th>VACUNACION</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>FIEBRE</th>\n",
       "      <th>COMPLICACIONES</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>DIAGNOSTICO</th>\n",
       "      <th>CRITERIO_DIAGNOSTICO</th>\n",
       "      <th>FECHA_DIAGNOSTICO</th>\n",
       "      <th>ORIGEN_CASO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FECHA_ACTUALIZACION, ID_REGISTRO, EDAD_ANOS, EDAD_MESES, EDAD_DIAS, SEXO, HABLA_LENGUA_INDIG, INDIGENA, ENTIDAD_UM_NOTIF, MUNICIPIO_UM_NOTIF, ENTIDAD_RES, MUNICIPIO_RES, INSTITUCION_NOTIF, VACUNACION, EXANTEMA, FIEBRE, COMPLICACIONES, DEFUNCION, DIAGNOSTICO, CRITERIO_DIAGNOSTICO, FECHA_DIAGNOSTICO, ORIGEN_CASO]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unreasable ages\n",
    "febriles_df[(febriles_df['EDAD_ANOS'] < 0) | (febriles_df['EDAD_ANOS'] >= 120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Data Type  Unique Values\n",
      "FECHA_ACTUALIZACION   datetime64[ns]              5\n",
      "ID_REGISTRO                    int64          10795\n",
      "EDAD_ANOS                      int64             87\n",
      "EDAD_MESES                     int64             12\n",
      "EDAD_DIAS                      int64             31\n",
      "SEXO                           int64              2\n",
      "HABLA_LENGUA_INDIG             int64              2\n",
      "INDIGENA                       int64              2\n",
      "ENTIDAD_UM_NOTIF               int64             32\n",
      "MUNICIPIO_UM_NOTIF             int64            172\n",
      "ENTIDAD_RES                    int64             35\n",
      "MUNICIPIO_RES                  int64            200\n",
      "INSTITUCION_NOTIF              int64             11\n",
      "VACUNACION                     int64              2\n",
      "EXANTEMA                       int64              1\n",
      "FIEBRE                       float64              1\n",
      "COMPLICACIONES                 int64              2\n",
      "DEFUNCION                      int64              2\n",
      "DIAGNOSTICO                    int64              2\n",
      "CRITERIO_DIAGNOSTICO           int64              3\n",
      "FECHA_DIAGNOSTICO     datetime64[ns]           1325\n",
      "ORIGEN_CASO                  float64              4\n"
     ]
    }
   ],
   "source": [
    "# Show the type of data in each column and all the possible unique values, store it in a dataframe\n",
    "data_types = pd.DataFrame(febriles_df.dtypes, columns=['Data Type'])\n",
    "unique_values = pd.DataFrame(febriles_df.nunique(), columns=['Unique Values'])\n",
    "data_types = data_types.join(unique_values)\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGEN:\n",
    "- 1 : IMPORTADO\n",
    "- 2: RELACIONADO A IMPORTACIÓN\n",
    "- 3: AUTÓCTONO\n",
    "- 4 : FUENTE DESCONOCIDA\n",
    "- 5 : NO APLICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ORIGEN_CASO' column to integer\n",
    "febriles_df['ORIGEN_CASO'] = febriles_df['ORIGEN_CASO'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "febriles_df.to_csv('Clean_Febriles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfermedades Transmitidas por Vectores (Dengue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames have identical columns.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dengue_2024 = pd.read_csv('Dengue/dengue_2024.csv')\n",
    "dengue_2023 = pd.read_csv('Dengue/dengue_2023.csv')\n",
    "dengue_2022 = pd.read_csv('Dengue/dengue_2022.csv')\n",
    "dengue_2021 = pd.read_csv('Dengue/dengue_2021.csv')\n",
    "dengue_2020 = pd.read_csv('Dengue/dengue_2020.csv')\n",
    "\n",
    "# Check if all column sets are identical\n",
    "columns_match = (dengue_2024.columns == dengue_2023.columns).all() and \\\n",
    "                (dengue_2023.columns == dengue_2022.columns).all() and \\\n",
    "                (dengue_2022.columns == dengue_2021.columns).all() and \\\n",
    "                (dengue_2021.columns == dengue_2020.columns).all()\n",
    "\n",
    "if columns_match:\n",
    "    print(\"All DataFrames have identical columns.\")\n",
    "    # Concatenate all DataFrames\n",
    "    dengue = pd.concat([dengue_2024, dengue_2023, dengue_2022, dengue_2021, dengue_2020])\n",
    "    dengue.to_csv('Dengue.csv', index=False)\n",
    "else:\n",
    "    # Calculate and print mismatches if columns differ\n",
    "    mismatch_count = sum(dengue_2024.columns != dengue_2023.columns) + \\\n",
    "                     sum(dengue_2023.columns != dengue_2022.columns) + \\\n",
    "                     sum(dengue_2022.columns != dengue_2021.columns) + \\\n",
    "                     sum(dengue_2021.columns != dengue_2020.columns)\n",
    "    print(\"Number of mismatched columns:\", mismatch_count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>EDAD_ANOS</th>\n",
       "      <th>ENTIDAD_RES</th>\n",
       "      <th>MUNICIPIO_RES</th>\n",
       "      <th>HABLA_LENGUA_INDIG</th>\n",
       "      <th>INDIGENA</th>\n",
       "      <th>ENTIDAD_UM_NOTIF</th>\n",
       "      <th>MUNICIPIO_UM_NOTIF</th>\n",
       "      <th>...</th>\n",
       "      <th>INMUNOSUPR</th>\n",
       "      <th>CIRROSIS_HEPATICA</th>\n",
       "      <th>EMBARAZO</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>DICTAMEN</th>\n",
       "      <th>TOMA_MUESTRA</th>\n",
       "      <th>RESULTADO_PCR</th>\n",
       "      <th>ESTATUS_CASO</th>\n",
       "      <th>ENTIDAD_ASIG</th>\n",
       "      <th>MUNICIPIO_ASIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>849113</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>873810</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>1299508</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>1299543</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>1299553</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA_ACTUALIZACION  ID_REGISTRO  SEXO  EDAD_ANOS  ENTIDAD_RES  \\\n",
       "0          2024-10-02       849113     2         35           12   \n",
       "1          2024-10-02       873810     2         55           18   \n",
       "2          2024-10-02      1299508     1          5           23   \n",
       "3          2024-10-02      1299543     2          3           27   \n",
       "4          2024-10-02      1299553     1         23           20   \n",
       "\n",
       "   MUNICIPIO_RES  HABLA_LENGUA_INDIG  INDIGENA  ENTIDAD_UM_NOTIF  \\\n",
       "0             29                   2         2                12   \n",
       "1             17                   2         2                18   \n",
       "2              5                   2         2                23   \n",
       "3              4                   2         2                27   \n",
       "4             67                   2         2                20   \n",
       "\n",
       "   MUNICIPIO_UM_NOTIF  ...  INMUNOSUPR CIRROSIS_HEPATICA  EMBARAZO  DEFUNCION  \\\n",
       "0                  29  ...           2                 2         2          2   \n",
       "1                  17  ...           2                 2         2          2   \n",
       "2                   5  ...           2                 2         2          2   \n",
       "3                   4  ...           2                 2         2          2   \n",
       "4                  67  ...           2                 2         2          2   \n",
       "\n",
       "   DICTAMEN  TOMA_MUESTRA  RESULTADO_PCR  ESTATUS_CASO  ENTIDAD_ASIG  \\\n",
       "0       5.0             1              5             3            12   \n",
       "1       5.0             2              5             1            18   \n",
       "2       5.0             1              5             3            23   \n",
       "3       5.0             2              5             1            27   \n",
       "4       5.0             2              5             1            20   \n",
       "\n",
       "   MUNICIPIO_ASIG  \n",
       "0              29  \n",
       "1              17  \n",
       "2               5  \n",
       "3               4  \n",
       "4              67  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dengue_df = pd.read_csv('Dengue.csv')\n",
    "dengue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 807955 entries, 0 to 807954\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   FECHA_ACTUALIZACION     807955 non-null  object \n",
      " 1   ID_REGISTRO             807955 non-null  int64  \n",
      " 2   SEXO                    807955 non-null  int64  \n",
      " 3   EDAD_ANOS               807955 non-null  int64  \n",
      " 4   ENTIDAD_RES             807955 non-null  int64  \n",
      " 5   MUNICIPIO_RES           807955 non-null  int64  \n",
      " 6   HABLA_LENGUA_INDIG      807955 non-null  int64  \n",
      " 7   INDIGENA                807955 non-null  int64  \n",
      " 8   ENTIDAD_UM_NOTIF        807955 non-null  int64  \n",
      " 9   MUNICIPIO_UM_NOTIF      807955 non-null  int64  \n",
      " 10  INSTITUCION_UM_NOTIF    807955 non-null  int64  \n",
      " 11  FECHA_SIGN_SINTOMAS     807955 non-null  object \n",
      " 12  TIPO_PACIENTE           807897 non-null  float64\n",
      " 13  HEMORRAGICOS            807955 non-null  int64  \n",
      " 14  DIABETES                807955 non-null  int64  \n",
      " 15  HIPERTENSION            807955 non-null  int64  \n",
      " 16  ENFERMEDAD_ULC_PEPTICA  807955 non-null  int64  \n",
      " 17  ENFERMEDAD_RENAL        807955 non-null  int64  \n",
      " 18  INMUNOSUPR              807955 non-null  int64  \n",
      " 19  CIRROSIS_HEPATICA       807955 non-null  int64  \n",
      " 20  EMBARAZO                807955 non-null  int64  \n",
      " 21  DEFUNCION               807955 non-null  int64  \n",
      " 22  DICTAMEN                807939 non-null  float64\n",
      " 23  TOMA_MUESTRA            807955 non-null  int64  \n",
      " 24  RESULTADO_PCR           807955 non-null  int64  \n",
      " 25  ESTATUS_CASO            807955 non-null  int64  \n",
      " 26  ENTIDAD_ASIG            807955 non-null  int64  \n",
      " 27  MUNICIPIO_ASIG          807955 non-null  int64  \n",
      "dtypes: float64(2), int64(24), object(2)\n",
      "memory usage: 172.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dengue_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01\n",
      "2024-09-28\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest 'FECHA_DIAGNOSTICO' dates\n",
    "print(dengue_df['FECHA_SIGN_SINTOMAS'].min())\n",
    "print(dengue_df['FECHA_SIGN_SINTOMAS'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 74\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# See if there are any missing values and duplicated rows\n",
    "print('Missing values:', dengue_df.isnull().sum().sum())\n",
    "print('Duplicated rows:', dengue_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_ACTUALIZACION</th>\n",
       "      <th>ID_REGISTRO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>EDAD_ANOS</th>\n",
       "      <th>ENTIDAD_RES</th>\n",
       "      <th>MUNICIPIO_RES</th>\n",
       "      <th>HABLA_LENGUA_INDIG</th>\n",
       "      <th>INDIGENA</th>\n",
       "      <th>ENTIDAD_UM_NOTIF</th>\n",
       "      <th>MUNICIPIO_UM_NOTIF</th>\n",
       "      <th>...</th>\n",
       "      <th>INMUNOSUPR</th>\n",
       "      <th>CIRROSIS_HEPATICA</th>\n",
       "      <th>EMBARAZO</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>DICTAMEN</th>\n",
       "      <th>TOMA_MUESTRA</th>\n",
       "      <th>RESULTADO_PCR</th>\n",
       "      <th>ESTATUS_CASO</th>\n",
       "      <th>ENTIDAD_ASIG</th>\n",
       "      <th>MUNICIPIO_ASIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>849113</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772026</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>849113</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340281</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>852727</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777375</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>852727</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>873810</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797683</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>873810</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605285</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>912816</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656728</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>912816</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>1081911</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393450</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>1081911</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>1207499</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410644</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>1207499</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FECHA_ACTUALIZACION  ID_REGISTRO  SEXO  EDAD_ANOS  ENTIDAD_RES  \\\n",
       "0               2024-10-02       849113     2         35           12   \n",
       "772026          2020-12-30       849113     2         32           12   \n",
       "340281          2023-12-04       852727     1         50           16   \n",
       "777375          2020-12-30       852727     1         48           16   \n",
       "1               2024-10-02       873810     2         55           18   \n",
       "797683          2020-12-30       873810     2         52           18   \n",
       "605285          2022-11-28       912816     2         13           30   \n",
       "656728          2021-12-13       912816     2         13           30   \n",
       "301             2024-10-02      1081911     2         11           20   \n",
       "393450          2023-12-04      1081911     2         10           20   \n",
       "300             2024-10-02      1207499     1         51           17   \n",
       "410644          2023-12-04      1207499     1         51           17   \n",
       "\n",
       "        MUNICIPIO_RES  HABLA_LENGUA_INDIG  INDIGENA  ENTIDAD_UM_NOTIF  \\\n",
       "0                  29                   2         2                12   \n",
       "772026             29                   2         2                12   \n",
       "340281              6                   2         2                16   \n",
       "777375              6                   2         2                16   \n",
       "1                  17                   2         2                18   \n",
       "797683             17                   2         2                18   \n",
       "605285            131                   2         2                30   \n",
       "656728            131                   2         2                30   \n",
       "301                67                   2         2                20   \n",
       "393450             67                   2         2                20   \n",
       "300                11                   2         2                17   \n",
       "410644             11                   2         2                17   \n",
       "\n",
       "        MUNICIPIO_UM_NOTIF  ...  INMUNOSUPR CIRROSIS_HEPATICA  EMBARAZO  \\\n",
       "0                       29  ...           2                 2         2   \n",
       "772026                  29  ...           2                 2         2   \n",
       "340281                   6  ...           2                 2         2   \n",
       "777375                   6  ...           2                 2         2   \n",
       "1                       17  ...           2                 2         2   \n",
       "797683                  17  ...           2                 2         2   \n",
       "605285                 193  ...           2                 2         2   \n",
       "656728                 193  ...           2                 2         2   \n",
       "301                     67  ...           2                 2         2   \n",
       "393450                  67  ...           2                 2         2   \n",
       "300                     11  ...           2                 2         2   \n",
       "410644                  11  ...           2                 2         2   \n",
       "\n",
       "        DEFUNCION  DICTAMEN  TOMA_MUESTRA  RESULTADO_PCR  ESTATUS_CASO  \\\n",
       "0               2       5.0             1              5             3   \n",
       "772026          2       5.0             1              5             1   \n",
       "340281          2       5.0             1              5             3   \n",
       "777375          2       5.0             1              5             3   \n",
       "1               2       5.0             2              5             1   \n",
       "797683          2       5.0             2              5             1   \n",
       "605285          2       5.0             1              5             3   \n",
       "656728          2       5.0             1              5             3   \n",
       "301             2       5.0             2              5             1   \n",
       "393450          2       5.0             2              5             1   \n",
       "300             2       5.0             1              5             1   \n",
       "410644          2       5.0             2              5             1   \n",
       "\n",
       "        ENTIDAD_ASIG  MUNICIPIO_ASIG  \n",
       "0                 12              29  \n",
       "772026            12              29  \n",
       "340281            16               6  \n",
       "777375            16               6  \n",
       "1                 18              17  \n",
       "797683            18              17  \n",
       "605285            30             131  \n",
       "656728            30             131  \n",
       "301               20              67  \n",
       "393450            20              67  \n",
       "300               17              11  \n",
       "410644            17              11  \n",
       "\n",
       "[12 rows x 28 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the repeated 'ID_REGISTRO' indexes and print those rows\n",
    "repeated_IDS = dengue_df[dengue_df.duplicated(subset='ID_REGISTRO', keep=False)].sort_values('ID_REGISTRO')\n",
    "repeated_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807869, 28)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with missing values and repeated IDs\n",
    "dengue_df = dengue_df.dropna()\n",
    "dengue_df = dengue_df.drop(repeated_IDS.index)\n",
    "dengue_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 807869 entries, 2 to 807954\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   FECHA_ACTUALIZACION  807869 non-null  datetime64[ns]\n",
      " 1   FECHA_SIGN_SINTOMAS  807869 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2)\n",
      "memory usage: 18.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace invalid date entries with NaT and convert to datetime\n",
    "for col in ['FECHA_ACTUALIZACION', 'FECHA_SIGN_SINTOMAS']:\n",
    "    dengue_df[col] = dengue_df[col].replace(['9999-99-99'], pd.NaT)\n",
    "    dengue_df[col] = pd.to_datetime(dengue_df[col], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "# Check if dates were succesfully converted\n",
    "print(dengue_df[['FECHA_ACTUALIZACION', 'FECHA_SIGN_SINTOMAS']].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Data Type  Unique Values\n",
      "FECHA_ACTUALIZACION     datetime64[ns]              5\n",
      "ID_REGISTRO                      int64         807869\n",
      "SEXO                             int64              2\n",
      "EDAD_ANOS                        int64            120\n",
      "ENTIDAD_RES                      int64             35\n",
      "MUNICIPIO_RES                    int64            476\n",
      "HABLA_LENGUA_INDIG               int64              2\n",
      "INDIGENA                         int64              2\n",
      "ENTIDAD_UM_NOTIF                 int64             32\n",
      "MUNICIPIO_UM_NOTIF               int64            386\n",
      "INSTITUCION_UM_NOTIF             int64             15\n",
      "FECHA_SIGN_SINTOMAS     datetime64[ns]           1640\n",
      "TIPO_PACIENTE                  float64              2\n",
      "HEMORRAGICOS                     int64              2\n",
      "DIABETES                         int64              2\n",
      "HIPERTENSION                     int64              2\n",
      "ENFERMEDAD_ULC_PEPTICA           int64              2\n",
      "ENFERMEDAD_RENAL                 int64              2\n",
      "INMUNOSUPR                       int64              2\n",
      "CIRROSIS_HEPATICA                int64              2\n",
      "EMBARAZO                         int64              2\n",
      "DEFUNCION                        int64              2\n",
      "DICTAMEN                       float64              4\n",
      "TOMA_MUESTRA                     int64              2\n",
      "RESULTADO_PCR                    int64              5\n",
      "ESTATUS_CASO                     int64              3\n",
      "ENTIDAD_ASIG                     int64             36\n",
      "MUNICIPIO_ASIG                   int64            482\n"
     ]
    }
   ],
   "source": [
    "# Show the type of data in each column and all the possible unique values, store it in a dataframe\n",
    "data_types = pd.DataFrame(dengue_df.dtypes, columns=['Data Type'])\n",
    "unique_values = pd.DataFrame(dengue_df.nunique(), columns=['Unique Values'])\n",
    "data_types = data_types.join(unique_values)\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TIPO_PACIENTE' and 'DICTAMEN' columns to integer\n",
    "dengue_df['TIPO_PACIENTE'] = dengue_df['TIPO_PACIENTE'].astype(int)\n",
    "dengue_df['DICTAMEN'] = dengue_df['DICTAMEN'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unreasable ages\n",
    "dengue_df = dengue_df.drop(dengue_df[(dengue_df['EDAD_ANOS'] < 0) | (dengue_df['EDAD_ANOS'] >= 120)][['EDAD_ANOS']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "dengue_df.to_csv('Clean_Dengue.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morbilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1026480 entries, 0 to 1026479\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count    Dtype  \n",
      "---  ------    --------------    -----  \n",
      " 0   date      1026480 non-null  object \n",
      " 1   sickness  1026480 non-null  object \n",
      " 2   state     1026480 non-null  object \n",
      " 3   value     1026480 non-null  float64\n",
      " 4   year      1026480 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 39.2+ MB\n"
     ]
    }
   ],
   "source": [
    "morbilidad_df = pd.read_csv('Morbilidad.csv')\n",
    "#t2017 = pd.read_csv('t2017.csv', encoding='latin1')\n",
    "morbilidad_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sickness</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>accidentes laborales</td>\n",
       "      <td>aguascalientes</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>accidentes laborales</td>\n",
       "      <td>baja california</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>accidentes laborales</td>\n",
       "      <td>baja california sur</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>accidentes laborales</td>\n",
       "      <td>campeche</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>accidentes laborales</td>\n",
       "      <td>chiapas</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date              sickness                state  value  year\n",
       "0  1995-01-15  accidentes laborales       aguascalientes   36.0  1995\n",
       "1  1995-01-15  accidentes laborales      baja california   26.0  1995\n",
       "2  1995-01-15  accidentes laborales  baja california sur   62.0  1995\n",
       "3  1995-01-15  accidentes laborales             campeche  214.0  1995\n",
       "4  1995-01-15  accidentes laborales              chiapas  225.0  1995"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morbilidad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127,\n",
       " array(['accidentes laborales', 'alcoholismo', 'amibiano absceso hepatico',\n",
       "        'arterial hipertension', 'artritis reumatoide', 'ascariasis',\n",
       "        'asma', 'blando chancro', 'bocio', 'brucelosis',\n",
       "        'cancer cervico-uterino', 'candidiasis urogenital',\n",
       "        'cirrosis hepatica', 'cisticercosis', 'colera', 'conjuntivitis',\n",
       "        'dengue hemorragico', 'diabetes', 'difteria',\n",
       "        'efectos asociados vacunas', 'encefalitis venezolana',\n",
       "        'enfermedad cerebrovascular nueva',\n",
       "        'enfermedad exantematica febril',\n",
       "        'enfermedades corazon isquemicas', 'epilepsia todas formas',\n",
       "        'erisipela', 'escarlatina',\n",
       "        'estreptococicas faringitis amigdalitis angina', 'ferina',\n",
       "        'fiebre dengue clasico', 'fiebre manchada', 'fiebre reumatica',\n",
       "        'fiebre tifoidea', 'giardiasis', 'hepatitis-a aguda',\n",
       "        'hepatitis-b aguda', 'herpes genital', 'infeccion asintomatica',\n",
       "        'infeccion intestinal definida',\n",
       "        'infeccion tracto genitourinario gonococica',\n",
       "        'infecciones intestinales definidas', 'influenza',\n",
       "        'intoxicacion alimetaria bacteriana',\n",
       "        'intoxicacion picadura alacran', 'intoxicacion plaguicidas',\n",
       "        'intoxicacion ponzona animales', 'leishmaniasis', 'lepra',\n",
       "        'linfogranuloma venereo', 'meningitis', 'meningitis nuevos',\n",
       "        'meningoencefalitis primaria', 'murino tifo',\n",
       "        'neumonias bronconeumonias', 'oncocercosis', 'otras hepatitis',\n",
       "        'otras tuberculosis', 'paludismo', 'paralisis flacida aguda',\n",
       "        'parotiditis', 'pinto', 'poliomielitis', 'rabia', 'rubeola',\n",
       "        'salmonelosis', 'sarampion', 'sarna escabiasis',\n",
       "        'shigelosis gelosis', 'sida', 'sifilis adquirida',\n",
       "        'sifilis congenita', 'sindrome coqueluchoide', 'tabaquismo',\n",
       "        'teniasis', 'tetanos', 'tetanos neonatal', 'toxoplasmosis',\n",
       "        'tracoma', 'trafico accidentes ncop', 'tricomoniasis urogenital',\n",
       "        'tripanosomiasis', 'tuberculosis aparato respiratorio',\n",
       "        'tuberculosis nuevos', 'varicela', 'amebiasis intestinal',\n",
       "        'anencefalia', 'fiebre amarilla', 'fiebre recurrente',\n",
       "        'helmintiasis', 'infecciones respiratorias agudas',\n",
       "        'otitis aguda media', 'oxiuriasis', 'peste',\n",
       "        'defectos tubo neural', 'haemophilus influenzae',\n",
       "        'accidente peaton lesionado', 'accidentes vehiculos motor',\n",
       "        'cancer mama', 'desnutricion leve', 'desnutricion moderada',\n",
       "        'desnutricion severa', 'displasia cervical moderada',\n",
       "        'displasia cervical severa', 'duodenitis gastritis ulceras',\n",
       "        'enfermedad alcoholica higado', 'hepatitis virica',\n",
       "        'hipertensivos embarazo', 'infeccion vias urinarias',\n",
       "        'insuficiencia venosa periferica', 'intoxicacion alcohol aguda',\n",
       "        'leptospirosis', 'mordeduras', 'mucopurulenta conjuntivitis',\n",
       "        'quemaduras', 'rubeola congenita', 'triquinosis',\n",
       "        'tuberculosis tumor maligno', 'tumor maligno estomago',\n",
       "        'violencia intrafamiliar', 'virus papiloma humano',\n",
       "        'gingivitis periodontal', 'labio hendido paladar',\n",
       "        'mordeduras mamiferos otros', 'serpiente mordedura',\n",
       "        'espina bifida', 'parasitosis intestinales', 'obesidad nuevos'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morbilidad_df['sickness'].unique()), morbilidad_df['sickness'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Data Type  Unique Values\n",
      "date        object            312\n",
      "sickness    object            127\n",
      "state       object             35\n",
      "value      float64          27013\n",
      "year         int64             26\n"
     ]
    }
   ],
   "source": [
    "# Show the type of data in each column and all the possible unique values, store it in a dataframe\n",
    "data_types = pd.DataFrame(morbilidad_df.dtypes, columns=['Data Type'])\n",
    "unique_values = pd.DataFrame(morbilidad_df.nunique(), columns=['Unique Values'])\n",
    "data_types = data_types.join(unique_values)\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the dataframe\n",
    "# Keep only 2024 COVID19 data\n",
    "covid_df_24 = covid_df[covid_df['FECHA_ACTUALIZACION'].dt.year == 2024].copy()\n",
    "covid_df_24.shape\n",
    "\n",
    "# Store that data in a new file\n",
    "covid_df_24.to_csv('Clean_COVID19MEXICO2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Databases to SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load your cleaned datasets\n",
    "covid_df = pd.read_csv('Clean_Data/Clean_COVID19MEXICO2024.csv', \n",
    "                       parse_dates=['FECHA_ACTUALIZACION', 'FECHA_INGRESO', 'FECHA_SINTOMAS', 'FECHA_DEF'])\n",
    "febriles_df = pd.read_csv('Clean_Data/Clean_Febriles.csv', \n",
    "                          parse_dates=['FECHA_ACTUALIZACION', 'FECHA_DIAGNOSTICO'])\n",
    "dengue_df = pd.read_csv('Clean_Data/Clean_Dengue.csv', \n",
    "                        parse_dates=['FECHA_ACTUALIZACION', 'FECHA_SIGN_SINTOMAS'])\n",
    "morbilidad_df = pd.read_csv('Clean_Data/Morbilidad.csv', \n",
    "                            encoding='latin1')\n",
    "\n",
    "# Connect to SQLite database (create if doesn't exist)\n",
    "conn = sqlite3.connect(\"IMMS_Mexico.sqlite\")\n",
    "\n",
    "# Export to SQL tables\n",
    "covid_df.to_sql(\"Covid\", conn, if_exists=\"replace\", index=False)\n",
    "febriles_df.to_sql(\"Febriles\", conn, if_exists=\"replace\", index=False)\n",
    "dengue_df.to_sql(\"Dengue\", conn, if_exists=\"replace\", index=False)\n",
    "morbilidad_df.to_sql(\"Morbilidad\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid\n",
      "Febriles\n",
      "Dengue\n",
      "Morbilidad\n"
     ]
    }
   ],
   "source": [
    "# Check the tables in the SQLite database\n",
    "conn = sqlite3.connect(\"IMMS_Mexico.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "for table in cursor.fetchall():\n",
    "    print(table[0])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data\n",
    "covid_df = pd.read_csv('Clean_Data/Clean_COVID19MEXICO2024.csv', \n",
    "                       parse_dates=['FECHA_ACTUALIZACION', 'FECHA_INGRESO', 'FECHA_SINTOMAS', 'FECHA_DEF'])\n",
    "febriles_df = pd.read_csv('Clean_Data/Clean_Febriles.csv', \n",
    "                          parse_dates=['FECHA_ACTUALIZACION', 'FECHA_DIAGNOSTICO'])\n",
    "dengue_df = pd.read_csv('Clean_Data/Clean_Dengue.csv', \n",
    "                        parse_dates=['FECHA_ACTUALIZACION', 'FECHA_SIGN_SINTOMAS'])\n",
    "morbilidad_df = pd.read_csv('Clean_Data/Morbilidad.csv', \n",
    "                            encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame of confirmed cases by state with average age\n",
    "state_summary = covid_df.groupby('ENTIDAD_RES').agg({\n",
    "    'ID_REGISTRO': 'count',\n",
    "    'EDAD': 'mean',\n",
    "    'CLASIFICACION_FINAL': lambda x: (x == 1).sum(),  # Example: Count confirmed cases\n",
    "})\n",
    "#print(state_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_age_gender_distribution():\n",
    "    # Map gender for interpretability\n",
    "    covid_df['SEXO_LABEL'] = covid_df['SEXO'].map({1: 'Female', 2: 'Male'})\n",
    "    \n",
    "    # Create histogram\n",
    "    fig = px.histogram(\n",
    "        covid_df, \n",
    "        x=\"EDAD\", \n",
    "        color=\"SEXO_LABEL\", \n",
    "        title=\"Age and Gender Distribution\", \n",
    "        barmode=\"overlay\", \n",
    "        labels={\"EDAD\": \"Age\", \"SEXO_LABEL\": \"Gender\"},\n",
    "        color_discrete_map={'Male': \"#006EC1\", 'Female': \"#52BCEC\"},\n",
    "        nbins=50, \n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLASIFICACION_FINAL catalog for mapping\n",
    "clasificacion_df = pd.read_excel('Data_Dicts/diccionario_datos_covid/Catalogos_COVID.xlsx', sheet_name='Cat CLASIFICACION_FINAL_COVID')\n",
    "clasificacion_mapping = dict(zip(\n",
    "    clasificacion_df['CLAVE'], \n",
    "    ['Confirmed by association', 'Confirmed by decease', 'Confirmed by laboratory', 'Invalid', 'Not applicable', 'Suspected', 'Negative']\n",
    "))\n",
    "\n",
    "def covid_cases_over_time():\n",
    "    # Convert `Period` to string for Plotly compatibility\n",
    "    covid_df['FECHA_INGRESO_YEAR_MONTH'] = covid_df['FECHA_INGRESO'].dt.to_period('M').astype(str)\n",
    "    \n",
    "    # Group data by classification and time\n",
    "    cases_by_time = covid_df.groupby(['FECHA_INGRESO_YEAR_MONTH', 'CLASIFICACION_FINAL']).size().reset_index(name='Count')\n",
    "    \n",
    "    # Map classification codes to labels\n",
    "    cases_by_time['CLASIFICACION_FINAL_LABEL'] = cases_by_time['CLASIFICACION_FINAL'].map(clasificacion_mapping)\n",
    "    \n",
    "    # Line chart for cases over time\n",
    "    fig = px.line(\n",
    "        cases_by_time, \n",
    "        x=\"FECHA_INGRESO_YEAR_MONTH\", \n",
    "        y=\"Count\", \n",
    "        color=\"CLASIFICACION_FINAL_LABEL\", \n",
    "        title=\"COVID-19 Cases Over Time by Classification\",\n",
    "        labels={\"FECHA_INGRESO_YEAR_MONTH\": \"Year-Month\", \"Count\": \"Cases\", \"CLASIFICACION_FINAL_LABEL\": \"Classification\"},\n",
    "        template=\"seaborn\",\n",
    "        color_discrete_sequence=px.colors.cyclical.Phase\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geojson file\n",
    "with open('geojsons/mexico.json') as file:\n",
    "    mexico = json.load(file)\n",
    "    \n",
    "# Load entidad catalog for mapping\n",
    "entidades_df = pd.read_excel('Data_Dicts/diccionario_datos_covid/Catalogos_COVID.xlsx', sheet_name='Catálogo de ENTIDADES')\n",
    "entidades_mapping = dict(zip(\n",
    "    entidades_df['CLAVE_ENTIDAD'], \n",
    "    entidades_df['ENTIDAD_FEDERATIVA'].str.title()  # Match GeoJSON property\n",
    "))\n",
    "\n",
    "for i, name in zip([30, 16, 5, 9], ['Veracruz', 'Michoacán', 'Coahuila', 'Ciudad de México']):\n",
    "    entidades_mapping[i] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_cases_geospatial():\n",
    "    # Map state codes to state names\n",
    "    covid_df['STATE_LABEL'] = covid_df['ENTIDAD_RES'].map(entidades_mapping)\n",
    "    \n",
    "    # Aggregate cases by state\n",
    "    cases_by_state = covid_df.groupby('STATE_LABEL').size().reset_index(name='Case_Count')\n",
    "    \n",
    "    # Geospatial distribution of cases\n",
    "    fig = px.choropleth(\n",
    "        cases_by_state, \n",
    "        locations=\"STATE_LABEL\", \n",
    "        geojson=mexico, \n",
    "        featureidkey=\"properties.name\", \n",
    "        color=\"Case_Count\", \n",
    "        title=\"COVID-19 Cases by State\",\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        range_color=(0, 150000),\n",
    "        labels={\"Case_Count\": \"Cases\"},\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "    fig.update_geos(\n",
    "        scope=\"north america\", \n",
    "        center={\"lat\": 23.6345, \"lon\": -102.5528}, \n",
    "        projection_scale=4.5\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_comorbidity_heatmap():\n",
    "    # Select comorbidities columns\n",
    "    comorbidities = sorted([\"DIABETES\", \"EPOC\", \"ASMA\", \"HIPERTENSION\", \"OBESIDAD\", \n",
    "                     \"RENAL_CRONICA\", \"TABAQUISMO\", \"OTRA_COM\", \"CARDIOVASCULAR\",\n",
    "                     'NEUMONIA', 'EMBARAZO', 'INMUSUPR', 'RENAL_CRONICA'])\n",
    "    comorbidity_data = covid_df[comorbidities]\n",
    "    \n",
    "    # Correlation matrix heatmap\n",
    "    fig = px.imshow(\n",
    "        comorbidity_data.corr(), \n",
    "        text_auto=True, \n",
    "        title=\"Comorbidity Co-occurrence Heatmap\", \n",
    "        color_continuous_scale=\"Blues\",\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_symptoms_to_admission():\n",
    "    # Calculate interval from symptoms to admission\n",
    "    covid_df['SYMPTOMS_TO_ADMISSION'] = (covid_df['FECHA_INGRESO'] - covid_df['FECHA_SINTOMAS']).dt.days\n",
    "    \n",
    "    # Histogram for the interval, cropped to 0-50 days\n",
    "    fig = px.histogram(\n",
    "        covid_df[covid_df['SYMPTOMS_TO_ADMISSION'] <= 50],  \n",
    "        x='SYMPTOMS_TO_ADMISSION', \n",
    "        nbins=50,  \n",
    "        title='Symptoms to Admission Interval (0-50 Days)',\n",
    "        labels={'SYMPTOMS_TO_ADMISSION': 'Days', 'count': 'Number of Cases'},\n",
    "        template='seaborn'\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dengue_age_gender_distribution():\n",
    "    # Map gender to labels\n",
    "    dengue_df['SEXO_LABEL'] = dengue_df['SEXO'].map({1: 'Female', 2: 'Male'})\n",
    "\n",
    "    # Facet histogram for age distribution by gender\n",
    "    fig = px.histogram(\n",
    "        dengue_df,\n",
    "        x='EDAD_ANOS',\n",
    "        facet_col='SEXO_LABEL',\n",
    "        color='SEXO_LABEL',\n",
    "        title='Age Distribution by Gender',\n",
    "        labels={'EDAD_ANOS': 'Age (Years)', 'SEXO_LABEL': 'Gender'},\n",
    "        color_discrete_map={'Male': \"#52BCEC\", 'Female': \"#006EC1\"},\n",
    "        nbins=30,\n",
    "        template='seaborn'\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dengue_cases_over_time():\n",
    "    # Extract month and year from symptoms date\n",
    "    dengue_df['FECHA_SINTOMAS_MONTH'] = dengue_df['FECHA_SIGN_SINTOMAS'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # Group by month-year to calculate cases\n",
    "    cases_by_time = dengue_df.groupby('FECHA_SINTOMAS_MONTH').size().reset_index(name='Cases')\n",
    "\n",
    "    # Create combined bar and line chart\n",
    "    fig = px.bar(\n",
    "        cases_by_time,\n",
    "        x='FECHA_SINTOMAS_MONTH',\n",
    "        y='Cases',\n",
    "        title='Dengue Cases Over Time',\n",
    "        labels={'FECHA_SINTOMAS_MONTH': 'Date (Year-Month)', 'Cases': 'Number of Cases'},\n",
    "        template='seaborn',\n",
    "        color_discrete_sequence=['#89D1F3'],\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=cases_by_time['FECHA_SINTOMAS_MONTH'],\n",
    "        y=cases_by_time['Cases'],\n",
    "        mode='lines',\n",
    "        name='Trend',\n",
    "        line=dict(color='#006EC1')\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dengue_hemorrhagic_cases_pie():\n",
    "    hemorrhagic_counts = dengue_df['HEMORRAGICOS'].value_counts().reset_index()\n",
    "    hemorrhagic_counts.columns = ['Hemorrhagic', 'Count']\n",
    "    hemorrhagic_counts['Hemorrhagic'] = hemorrhagic_counts['Hemorrhagic'].map({2: 'Non-Hemorrhagic', 1: 'Hemorrhagic'})\n",
    "\n",
    "    fig = px.pie(\n",
    "        hemorrhagic_counts,\n",
    "        names='Hemorrhagic',\n",
    "        values='Count',\n",
    "        title='Proportion of Hemorrhagic Dengue Cases',\n",
    "        template='seaborn',\n",
    "        color_discrete_sequence=['#006EC1', '#89D1F3']\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dengue_comorbidity_heatmap():\n",
    "    # Select comorbidities columns\n",
    "    comorbidities = ['DIABETES', 'HIPERTENSION', 'ENFERMEDAD_ULC_PEPTICA', 'INMUNOSUPR']\n",
    "    comorbidity_data = dengue_df[comorbidities].copy()\n",
    "    comorbidity_data = comorbidity_data.replace(2, 0)\n",
    "\n",
    "    # Generate the heatmap\n",
    "    fig = px.imshow(\n",
    "        comorbidity_data.corr(), \n",
    "        text_auto=True,  \n",
    "        title=\"Comorbidity Co-occurrence Heatmap\", \n",
    "        color_continuous_scale=\"Blues\", \n",
    "        labels={\"color\": \"Correlation\"},\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def febriles_parallel_categories():\n",
    "    # Map variables to human-readable labels using catalogs\n",
    "    febriles_df['SEXO_LABEL'] = febriles_df['SEXO'].map({1: 'Female', 2: 'Male'})\n",
    "    febriles_df['VACUNACION_LABEL'] = febriles_df['VACUNACION'].map({1: 'Yes', 2: 'No'})\n",
    "    febriles_df['DEFUNCION_LABEL'] = febriles_df['DEFUNCION'].map({1: 'Yes', 2: 'No'})\n",
    "    febriles_df['COMPLICACIONES_LABEL'] = febriles_df['COMPLICACIONES'].map({1: 'Yes', 2: 'No'})\n",
    "    \n",
    "    fig = px.parallel_categories(\n",
    "        febriles_df, \n",
    "        dimensions=['SEXO_LABEL', 'VACUNACION_LABEL', 'DEFUNCION_LABEL', 'COMPLICACIONES_LABEL'],\n",
    "        title='Parallel Categories for Febriles Dataset',\n",
    "        labels={\n",
    "            'SEXO_LABEL': 'Gender',\n",
    "            'VACUNACION_LABEL': 'Vaccination',\n",
    "            'DEFUNCION_LABEL': 'Death',\n",
    "            'COMPLICACIONES_LABEL': 'Complications'\n",
    "        },\n",
    "        template='seaborn',\n",
    "        color='COMPLICACIONES',\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "        \n",
    "    )\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def febriles_strip_plot():\n",
    "    # Map categorical variables to labels\n",
    "    febriles_df['VACUNACION_LABEL'] = febriles_df['VACUNACION'].map({2: 'No', 1: 'Yes'})\n",
    "    febriles_df['COMPLICACIONES_LABEL'] = febriles_df['COMPLICACIONES'].map({2: 'No', 1: 'Yes'})\n",
    "\n",
    "    # Create a strip plot\n",
    "    fig = px.strip(\n",
    "        febriles_df,\n",
    "        x='VACUNACION_LABEL',\n",
    "        y='EDAD_ANOS',\n",
    "        color='COMPLICACIONES_LABEL',\n",
    "        title='Age vs. Vaccination and Complications',\n",
    "        labels={\n",
    "            'VACUNACION_LABEL': 'Vaccination Status',\n",
    "            'EDAD_ANOS': 'Age (Years)',\n",
    "            'COMPLICACIONES_LABEL': 'Complications'\n",
    "        },\n",
    "        template='seaborn',\n",
    "        stripmode='overlay',\n",
    "        color_discrete_map={'Yes': '#B5E5F9', 'No': '#006EC1'}\n",
    "    )\n",
    "    fig.update_traces(jitter=0.3, marker=dict(size=8))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def febriles_geospatial_distribution():\n",
    "    # Map state codes to names\n",
    "    febriles_df['STATE_LABEL'] = febriles_df['ENTIDAD_RES'].map(entidades_mapping)\n",
    "    \n",
    "    # Group by state for case counts\n",
    "    cases_by_state = febriles_df.groupby('STATE_LABEL').size().reset_index(name='Case_Count')\n",
    "    \n",
    "    # Create choropleth map\n",
    "    fig = px.choropleth(\n",
    "        cases_by_state,\n",
    "        geojson=mexico,  # Use GeoJSON for Mexican states\n",
    "        locations='STATE_LABEL',\n",
    "        featureidkey='properties.name',\n",
    "        color='Case_Count',\n",
    "        title='Geospatial Distribution of Febriles Cases',\n",
    "        color_continuous_scale='Blues',\n",
    "        labels={'Case_Count': 'Cases'},\n",
    "        range_color=(0, 1500),\n",
    "        template='seaborn'\n",
    "    )\n",
    "    fig.update_geos(\n",
    "        scope='north america',\n",
    "        center={'lat': 23.6345, 'lon': -102.5528},\n",
    "        projection_scale=4.5,\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "morbilidad_df[['state', 'sickness']] = morbilidad_df[['state', 'sickness']].apply(lambda x: x.str.title())\n",
    "\n",
    "def morbilidad_top_diseases_over_time():\n",
    "    # Group data by year and sickness, summing up the cases\n",
    "    top_diseases = (\n",
    "        morbilidad_df.groupby(['year', 'sickness'])['value'].sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by='value', ascending=False)\n",
    "    )\n",
    "\n",
    "    # Select the top 10 diseases overall\n",
    "    top_10_diseases = top_diseases.groupby('sickness')['value'].sum().nlargest(10).index\n",
    "\n",
    "    # Filter data to include only top 10 diseases\n",
    "    filtered_data = top_diseases[top_diseases['sickness'].isin(top_10_diseases)]\n",
    "\n",
    "    # Create a grouped bar chart\n",
    "    fig = px.bar(\n",
    "        filtered_data,\n",
    "        x='year',\n",
    "        y='value',\n",
    "        color='sickness',\n",
    "        barmode='group', \n",
    "        title='Top 10 Diseases Over Time',\n",
    "        labels={'year': 'Year', 'value': 'Cases', 'sickness': 'Disease'},\n",
    "        template='seaborn',\n",
    "        color_discrete_sequence=px.colors.cyclical.Phase\n",
    "    )\n",
    "\n",
    "    # Update layout for better appearance\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Number of Cases\",\n",
    "        legend_title=\"Disease\",\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping for duplicate or inconsistent state names\n",
    "state_mapping = {\n",
    "    'Distrito Federal': 'Ciudad de México',\n",
    "    'Sanluis Potosi': 'San Luis Potosí',\n",
    "    'Queretaro': 'Querétaro',\n",
    "    'Mexico': 'México',\n",
    "    'Michoacan': 'Michoacán',\n",
    "    'Nuevo Leon': 'Nuevo León',\n",
    "    'Yucatan': 'Yucatán',\n",
    "    'Coahuila': 'Coahuila',\n",
    "    'Veracruz': 'Veracruz',\n",
    "    'Ciudad De Mexico': 'Ciudad de México',\n",
    "    'San Luis Potosi': 'San Luis Potosí',\n",
    "    'Total Global': None  # Remove non-geographic entry\n",
    "}\n",
    "\n",
    "# Apply mapping to standardize state names\n",
    "morbilidad_df['state'] = morbilidad_df['state'].replace(state_mapping)\n",
    "invalid_states = {'Estados Unidos Mexicanos', 'Se Ignora', 'No Especificado', 'No Aplica', None}\n",
    "morbilidad_df = morbilidad_df[~morbilidad_df['state'].isin(invalid_states)]\n",
    "\n",
    "def morbilidad_treemap():\n",
    "    # Aggregate cases by state and sickness\n",
    "    treemap_data = (\n",
    "        morbilidad_df.groupby(['state', 'sickness'])['value'].sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by='value', ascending=False)\n",
    "    )\n",
    "\n",
    "    treemap_data = treemap_data[treemap_data['value'] > 0]\n",
    "    \n",
    "    # Create a treemap\n",
    "    fig = px.treemap(\n",
    "        treemap_data,\n",
    "        path=['state', 'sickness'],\n",
    "        values='value',\n",
    "        title='Distribution of Cases by State and Disease',\n",
    "        labels={'state': 'State', 'sickness': 'Disease', 'value': 'Cases'},\n",
    "        template='seaborn',\n",
    "        color='value',\n",
    "        range_color=(0, 80000000),\n",
    "        color_continuous_scale=px.colors.sequential.Blues,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morbilidad_geospatial_distribution():\n",
    "    # Aggregate cases by state\n",
    "    cases_by_state = (\n",
    "        morbilidad_df.groupby('state')['value'].sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={'value': 'Total_Cases'})\n",
    "    )\n",
    "\n",
    "    # Create a choropleth map\n",
    "    fig = px.choropleth(\n",
    "        cases_by_state,\n",
    "        geojson=mexico,  \n",
    "        locations='state',\n",
    "        featureidkey='properties.name',\n",
    "        color='Total_Cases',\n",
    "        title='Geospatial Distribution of Total Cases',\n",
    "        labels={'state': 'State', 'Total_Cases': 'Total Cases'},\n",
    "        color_continuous_scale='Blues',\n",
    "        template='seaborn',\n",
    "    )\n",
    "    fig.update_geos(\n",
    "        scope='north america',\n",
    "        center={'lat': 23.6345, 'lon': -102.5528},\n",
    "        projection_scale=4.5,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "def anova_age_across_datasets():\n",
    "    \"\"\"\n",
    "    Perform ANOVA on age across datasets (COVID, Dengue, Febriles) and visualize the results.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    covid_age = covid_df['EDAD']\n",
    "    dengue_age = dengue_df['EDAD_ANOS']\n",
    "    febriles_age = febriles_df['EDAD_ANOS']\n",
    "\n",
    "    # Perform ANOVA\n",
    "    anova_result = f_oneway(covid_age, dengue_age, febriles_age)\n",
    "    \n",
    "    # Create a summary text\n",
    "    summary_text = (\n",
    "        f\"ANOVA Results:\\n\"\n",
    "        f\"F-statistic: {anova_result.statistic:.2f}\\n\"\n",
    "        f\"P-value: {anova_result.pvalue:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Boxplot for visualizing age distribution across datasets\n",
    "    all_ages = pd.DataFrame({\n",
    "        'Dataset': ['COVID'] * len(covid_age) + ['Dengue'] * len(dengue_age) + ['Febriles'] * len(febriles_age),\n",
    "        'Age': pd.concat([covid_age, dengue_age, febriles_age])\n",
    "    })\n",
    "\n",
    "    fig = px.box(\n",
    "        all_ages,\n",
    "        x='Dataset',\n",
    "        y='Age',\n",
    "        title=\"Age Distribution Across Datasets (ANOVA)\",\n",
    "        labels={'Age': 'Age (Years)', 'Dataset': 'Dataset'},\n",
    "        template='seaborn',\n",
    "        color='Dataset',\n",
    "        color_discrete_map={'COVID': '#006EC1', 'Dengue': '#52BCEC', 'Febriles': '#89D1F3'},\n",
    "    )\n",
    "    \n",
    "    # Add ANOVA summary text\n",
    "    fig.add_annotation(\n",
    "        x=1.5, y=max(all_ages['Age']),\n",
    "        text=summary_text,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color=\"black\"),\n",
    "        align=\"left\",\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\",\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manova_covid_dengue():\n",
    "    \"\"\"\n",
    "    Perform MANOVA on COVID and Dengue datasets for comorbidities and return a summary table.\n",
    "    \"\"\"\n",
    "    # Combine datasets with selected variables\n",
    "    selected_columns = ['DIABETES', 'HIPERTENSION', 'EMBARAZO']\n",
    "    covid_comorbid = covid_df[selected_columns].assign(Dataset='COVID')\n",
    "    dengue_comorbid = dengue_df[selected_columns].assign(Dataset='Dengue')\n",
    "\n",
    "    combined_data = pd.concat([covid_comorbid, dengue_comorbid])\n",
    "\n",
    "    # Perform MANOVA\n",
    "    manova = MANOVA.from_formula('DIABETES + HIPERTENSION + EMBARAZO ~ Dataset', data=combined_data)\n",
    "    manova_result = manova.mv_test()\n",
    "\n",
    "    # Extract MANOVA results into a readable DataFrame\n",
    "    dataset_results = manova_result.results['Dataset']['stat']\n",
    "    summary_table = dataset_results.reset_index().rename(columns={\n",
    "        'index': 'Test',\n",
    "        'Value': 'Statistic',\n",
    "        'F Value': 'F-value',\n",
    "        'Num DF': 'Num DF',\n",
    "        'Den DF': 'Den DF',\n",
    "        'Pr > F': 'p-value'\n",
    "    })\n",
    "\n",
    "    # Filter to keep only the first two rows\n",
    "    summary_table = summary_table.iloc[:2]\n",
    "    \n",
    "    # Round results\n",
    "    numeric_cols = ['Statistic', 'F-value', 'Num DF', 'Den DF', 'p-value']\n",
    "    summary_table[numeric_cols] = summary_table[numeric_cols].apply(pd.to_numeric).round(3)\n",
    "\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manova_covid_single():\n",
    "    \"\"\"\n",
    "    Perform MANOVA on the COVID dataset for comorbidities by TIPO_PACIENTE (Ambulatory vs Hospitalized).\n",
    "    \"\"\"\n",
    "    # Filter COVID data for valid TIPO_PACIENTE values\n",
    "    covid_filtered = covid_df[covid_df['TIPO_PACIENTE'].isin([1, 2])]\n",
    "\n",
    "    # Perform MANOVA\n",
    "    manova = MANOVA.from_formula('DIABETES + HIPERTENSION + ASMA + EPOC + OBESIDAD ~ TIPO_PACIENTE', data=covid_filtered)\n",
    "    manova_result = manova.mv_test()\n",
    "\n",
    "    # Extract MANOVA results into a readable DataFrame\n",
    "    tipo_paciente_results = manova_result.results['TIPO_PACIENTE']['stat']\n",
    "    summary_table = tipo_paciente_results.reset_index().rename(columns={\n",
    "        'index': 'Test',\n",
    "        'Value': 'Statistic',\n",
    "        'F Value': 'F-value',\n",
    "        'Num DF': 'Num DF',\n",
    "        'Den DF': 'Den DF',\n",
    "        'Pr > F': 'p-value'\n",
    "    })\n",
    "    \n",
    "    # Filter to keep only the first two rows\n",
    "    summary_table = summary_table.iloc[:2]\n",
    "\n",
    "    # Round results\n",
    "    numeric_cols = ['Statistic', 'F-value', 'Num DF', 'Den DF', 'p-value']\n",
    "    summary_table[numeric_cols] = summary_table[numeric_cols].apply(pd.to_numeric).round(3)\n",
    "\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_dengue_clustering():\n",
    "    \"\"\"\n",
    "    Perform K-Means clustering on numerical variables in the Dengue dataset with improved visualization.\n",
    "    \"\"\"\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    \n",
    "    # Select relevant numerical columns and preprocess\n",
    "    features = ['EDAD_ANOS', 'FECHA_SIGN_SINTOMAS', 'DIABETES', 'HIPERTENSION']\n",
    "    dengue_features = dengue_df[features].copy()\n",
    "    dengue_features['FECHA_SIGN_SINTOMAS'] = (\n",
    "        (dengue_df['FECHA_SIGN_SINTOMAS'] - dengue_df['FECHA_SIGN_SINTOMAS'].min()).dt.days\n",
    "    )\n",
    "    dengue_features = dengue_features.fillna(0)  # Handle NaNs\n",
    "\n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(dengue_features)\n",
    "\n",
    "    # Apply K-Means\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    dengue_df['Cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "    # Map clusters to distinct colors\n",
    "    cluster_colors = {0: '0', 1: '1', 2: '2'}\n",
    "    dengue_df['Cluster_Color'] = dengue_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "    # Create scatter plot with discrete colors\n",
    "    fig = px.scatter(\n",
    "        dengue_df,\n",
    "        x='EDAD_ANOS',\n",
    "        y='FECHA_SIGN_SINTOMAS',\n",
    "        color='Cluster_Color',\n",
    "        color_discrete_map={'0': '#006EC1', '1': '#009EE5', '2': '#89D1F3'},\n",
    "        title=\"K-Means Clustering of Dengue Cases\",\n",
    "        labels={'EDAD_ANOS': 'Age (Years)', 'FECHA_SIGN_SINTOMAS': 'Days Since First Symptom', 'Cluster_Color': 'Cluster'},\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    # Add cluster labels\n",
    "    for cluster in dengue_df['Cluster'].unique():\n",
    "        cluster_data = dengue_df[dengue_df['Cluster'] == cluster]\n",
    "        mean_x = cluster_data['EDAD_ANOS'].mean()\n",
    "        mean_y = cluster_data['FECHA_SIGN_SINTOMAS'].mean()\n",
    "        fig.add_annotation(\n",
    "            x=mean_x,\n",
    "            y=mean_y,\n",
    "            text=str(cluster),\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowsize=1,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='black',\n",
    "            font=dict(color='black', size=12),\n",
    "            bgcolor=\"white\",\n",
    "            bordercolor=\"black\"\n",
    "        )\n",
    "        \n",
    "    # Add annotation explaining variable roles\n",
    "    fig.add_annotation(\n",
    "        text=(\n",
    "            \"Indicators used for clustering:<br>\"\n",
    "            \"- Diabetes <br>\" \n",
    "            \"- Hypertension\"\n",
    "        ),\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.95, y=1.2,  # Position the annotation outside the plot\n",
    "        showarrow=False,\n",
    "        align=\"left\",\n",
    "        font=dict(size=12),\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\"\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef gmm_covid_clustering():\\n    \\n    #Perform GMM clustering on the COVID dataset based on age, comorbidities, and admission timelines with improved visualization.\\n    \\n    # Address potential OpenMP conflict\\n    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\\n\\n    # Select features for clustering\\n    covid_df[\\'SYMPTOMS_TO_ADMISSION\\'] = (covid_df[\\'FECHA_INGRESO\\'] - covid_df[\\'FECHA_SINTOMAS\\']).dt.days\\n    features = [\\'EDAD\\', \\'SYMPTOMS_TO_ADMISSION\\', \\'DIABETES\\', \\'HIPERTENSION\\']\\n    covid_features = covid_df[features].fillna(0)\\n\\n    # Standardize features\\n    scaled_features = StandardScaler().fit_transform(covid_features)\\n\\n    # Apply GMM\\n    covid_df[\\'Cluster\\'] = GaussianMixture(n_components=3, random_state=42).fit_predict(scaled_features)\\n\\n    # Map clusters to distinct colors\\n    cluster_colors = {0: \\'0\\', 1: \\'1\\', 2: \\'2\\'}\\n    covid_df[\\'Cluster_Label\\'] = covid_df[\\'Cluster\\'].map(cluster_colors)\\n\\n    # Create scatter plot with discrete colors\\n    fig = px.scatter(\\n        covid_df,\\n        x=\\'EDAD\\',\\n        y=\\'SYMPTOMS_TO_ADMISSION\\',\\n        color=\\'Cluster_Label\\',\\n        color_discrete_map={\\n            \\'0\\': \\'#006EC1\\',\\n            \\'1\\': \\'#009EE5\\',\\n            \\'2\\': \\'#89D1F3\\'\\n        },\\n        title=\"GMM Clustering of COVID Cases\",\\n        labels={\\n            \\'EDAD\\': \\'Age (Years)\\', \\n            \\'SYMPTOMS_TO_ADMISSION\\': \\'Days from Symptoms to Admission\\', \\n            \\'Cluster_Label\\': \\'Cluster\\'\\n        },\\n        template=\"seaborn\"\\n    )\\n\\n    return fig\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def gmm_covid_clustering():\n",
    "    \n",
    "    #Perform GMM clustering on the COVID dataset based on age, comorbidities, and admission timelines with improved visualization.\n",
    "    \n",
    "    # Address potential OpenMP conflict\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "    # Select features for clustering\n",
    "    covid_df['SYMPTOMS_TO_ADMISSION'] = (covid_df['FECHA_INGRESO'] - covid_df['FECHA_SINTOMAS']).dt.days\n",
    "    features = ['EDAD', 'SYMPTOMS_TO_ADMISSION', 'DIABETES', 'HIPERTENSION']\n",
    "    covid_features = covid_df[features].fillna(0)\n",
    "\n",
    "    # Standardize features\n",
    "    scaled_features = StandardScaler().fit_transform(covid_features)\n",
    "\n",
    "    # Apply GMM\n",
    "    covid_df['Cluster'] = GaussianMixture(n_components=3, random_state=42).fit_predict(scaled_features)\n",
    "\n",
    "    # Map clusters to distinct colors\n",
    "    cluster_colors = {0: '0', 1: '1', 2: '2'}\n",
    "    covid_df['Cluster_Label'] = covid_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "    # Create scatter plot with discrete colors\n",
    "    fig = px.scatter(\n",
    "        covid_df,\n",
    "        x='EDAD',\n",
    "        y='SYMPTOMS_TO_ADMISSION',\n",
    "        color='Cluster_Label',\n",
    "        color_discrete_map={\n",
    "            '0': '#006EC1',\n",
    "            '1': '#009EE5',\n",
    "            '2': '#89D1F3'\n",
    "        },\n",
    "        title=\"GMM Clustering of COVID Cases\",\n",
    "        labels={\n",
    "            'EDAD': 'Age (Years)', \n",
    "            'SYMPTOMS_TO_ADMISSION': 'Days from Symptoms to Admission', \n",
    "            'Cluster_Label': 'Cluster'\n",
    "        },\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "from dash import html\n",
    "\n",
    "def hierarchical_clustering_covid():\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering on the COVID dataset using an optimized linkage method,\n",
    "    formatted to align with the dashboard's aesthetics.\n",
    "    \"\"\"\n",
    "    # Select features for clustering\n",
    "    features = ['TIPO_PACIENTE', 'DIABETES', 'HIPERTENSION', 'ASMA', 'EPOC', 'OBESIDAD']\n",
    "    covid_features = covid_df[features].fillna(0)\n",
    "\n",
    "    # Downsample the data\n",
    "    sample_size = 1000\n",
    "    covid_features_sampled = covid_features.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaled_features = StandardScaler().fit_transform(covid_features_sampled)\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(scaled_features, method='ward')\n",
    "\n",
    "    # Create dendrogram with updated aesthetics\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    dendrogram(\n",
    "        linkage_matrix,\n",
    "        truncate_mode='lastp',\n",
    "        p=20,\n",
    "        show_leaf_counts=True,\n",
    "        leaf_font_size=10,  # Match font size to dashboard's readability\n",
    "        above_threshold_color=\"#006EC1\",  # Consistent blue for unclustered segments\n",
    "        color_threshold=30,  # Adjust clustering cut-off color\n",
    "    )\n",
    "    plt.title(\"Hierarchical Clustering (Ward Linkage) for COVID Dataset\", fontsize=16, color=\"#333333\", pad=15)\n",
    "    plt.xlabel(\"Cluster Size\", fontsize=14, color=\"#333333\", labelpad=10)\n",
    "    plt.ylabel(\"Distance\", fontsize=14, color=\"#333333\", labelpad=10)\n",
    "    plt.xticks(fontsize=12, color=\"#333333\")  # Match axis tick labels with Plotly styling\n",
    "    plt.yticks(fontsize=12, color=\"#333333\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)  # Add light grid for readability\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure to the assets directory\n",
    "    plt.savefig('assets/hierarchical_clustering_covid_fast.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "    # Return dendrogram as an image component for Dash\n",
    "    fig = html.Div([\n",
    "        html.Img(\n",
    "            src='/assets/hierarchical_clustering_covid_fast.png',\n",
    "            style={\n",
    "                'height': 'auto',\n",
    "                'width': '100%',\n",
    "                'object-fit': 'contain',\n",
    "                'border': '1px solid #ccc',\n",
    "                'box-shadow': '0 4px 8px rgba(0, 0, 0, 0.1)',\n",
    "            }\n",
    "        ),\n",
    "        html.P(\n",
    "            \"Features used for clustering: TIPO_PACIENTE, Diabetes, Hypertension, Asthma, EPOC, Obesity\",\n",
    "            style={'text-align': 'center', 'margin-top': '10px', 'font-size': '14px'}\n",
    "        )\n",
    "    ])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "def kprototypes_febriles():\n",
    "    \"\"\"\n",
    "    Perform K-Prototypes clustering on Febriles dataset with categorical and numerical data.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    features = ['VACUNACION_LABEL', 'DEFUNCION_LABEL', 'COMPLICACIONES_LABEL', 'EDAD_ANOS']\n",
    "    febriles_features = febriles_df[features].copy()\n",
    "\n",
    "    # Encode categorical variables as integers\n",
    "    categorical_columns = ['VACUNACION_LABEL', 'DEFUNCION_LABEL', 'COMPLICACIONES_LABEL']\n",
    "    febriles_features[categorical_columns] = febriles_features[categorical_columns].apply(lambda col: col.astype('category').cat.codes)\n",
    "\n",
    "    # Downsample the dataset\n",
    "    sample_size = 1000 \n",
    "    febriles_sampled = febriles_features.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Convert to numpy array for K-Prototypes\n",
    "    data = febriles_sampled.values\n",
    "\n",
    "    # Apply K-Prototypes\n",
    "    kproto = KPrototypes(n_clusters=3, init='Cao', gamma=0.5, random_state=42)\n",
    "    clusters = kproto.fit_predict(data, categorical=[0, 1, 2])\n",
    "\n",
    "    # Add cluster labels to the dataframe\n",
    "    febriles_sampled['Cluster'] = clusters\n",
    "\n",
    "    # Create scatter plot for clustering\n",
    "    fig = px.scatter(\n",
    "        febriles_sampled,\n",
    "        x='EDAD_ANOS',\n",
    "        y='Cluster',\n",
    "        color='Cluster',\n",
    "        title=\"K-Prototypes Clustering on Febriles Dataset\",\n",
    "        labels={'EDAD_ANOS': 'Age (Years)', 'Cluster': 'Cluster'},\n",
    "        template=\"seaborn\",\n",
    "        color_discrete_map={0: '#006EC1', 1: '#009EE5', 2: '#89D1F3'}\n",
    "    )\n",
    "    \n",
    "    # Add annotation explaining variable roles\n",
    "    fig.add_annotation(\n",
    "        text=(\n",
    "            \"Indicators used for clustering:<br>\"\n",
    "            \"- Vaccination <br>\" \n",
    "            \"- Death <br>\"\n",
    "            \"- Complications\"\n",
    "        ),\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.95, y=1.25,  \n",
    "        showarrow=False,\n",
    "        align=\"left\",\n",
    "        font=dict(size=12),\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\"\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbaca/opt/anaconda3/envs/escuela4to/lib/python3.12/site-packages/threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "import plotly.express as px\n",
    "\n",
    "def time_series_clustering_morbidities():\n",
    "    \"\"\"\n",
    "    Perform time-series clustering on the morbidities dataset and create a Plotly line plot showing only cluster mean trends.\n",
    "    \"\"\"\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    \n",
    "    # Aggregate and Pivot Data\n",
    "    aggregated_data = (\n",
    "        morbilidad_df.groupby(['sickness', 'year'])['value']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    pivoted_data = aggregated_data.pivot(index='sickness', columns='year', values='value').fillna(0)\n",
    "\n",
    "    # Scale Data\n",
    "    scaler = TimeSeriesScalerMeanVariance()\n",
    "    scaled_time_series = scaler.fit_transform(pivoted_data.values)\n",
    "\n",
    "    # Apply Time-Series K-Means Clustering\n",
    "    n_clusters = 3\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=42)\n",
    "    clusters = model.fit_predict(scaled_time_series)\n",
    "\n",
    "    # Add Clusters to the Data and Aggregate Mean Trends\n",
    "    pivoted_data['Cluster'] = clusters\n",
    "    mean_trends = pivoted_data.groupby('Cluster').mean().reset_index().melt(\n",
    "        id_vars=['Cluster'], var_name='Year', value_name='Mean Value'\n",
    "    )\n",
    "\n",
    "    # Create Line Plot\n",
    "    fig = px.line(\n",
    "        mean_trends,\n",
    "        x='Year',\n",
    "        y='Mean Value',\n",
    "        color='Cluster',\n",
    "        title='Mean Time-Series Trends for Morbidities by Cluster',\n",
    "        labels={'Mean Value': 'Average Cases', 'Year': 'Year', 'Cluster': 'Cluster'},\n",
    "        template='seaborn',\n",
    "        color_discrete_sequence={0: '#006EC1', 1: '#009EE5', 2: '#89D1F3'}\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "\n",
    "def pca_covid():\n",
    "    \"\"\"\n",
    "    Perform PCA on the COVID dataset for dimensionality reduction and visualize the top 2 components.\n",
    "    \"\"\"\n",
    "    # Select features for PCA\n",
    "    features = ['EDAD', 'DIABETES', 'HIPERTENSION', 'ASMA', 'EPOC', 'OBESIDAD']\n",
    "    covid_features = covid_df[features].fillna(0)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(covid_features)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_results = pca.fit_transform(scaled_features)\n",
    "\n",
    "    # Add PCA components back to the dataframe\n",
    "    covid_df['PCA1'] = pca_results[:, 0]\n",
    "    covid_df['PCA2'] = pca_results[:, 1]\n",
    "\n",
    "    patient_colors = {1: 'Ambulatory', 2: 'Hospitalized'}\n",
    "    covid_df['TIPO_PACIENTE_Label'] = covid_df['TIPO_PACIENTE'].map(patient_colors)\n",
    "\n",
    "    # Create scatter plot for PCA results\n",
    "    fig = px.scatter(\n",
    "        covid_df,\n",
    "        x='PCA1',\n",
    "        y='PCA2',\n",
    "        title=\"PCA on COVID Dataset\",\n",
    "        color='TIPO_PACIENTE_Label',  # Use patient type for coloring\n",
    "        labels={\n",
    "            'PCA1': 'Principal Component 1',\n",
    "            'PCA2': 'Principal Component 2',\n",
    "            'TIPO_PACIENTE_Label': 'Patient Type'\n",
    "        },\n",
    "        template=\"seaborn\",\n",
    "        color_discrete_map={\n",
    "            'Ambulatory': '#006EC1',\n",
    "            'Hospitalized': '#89D1F3'\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Add explained variance as annotations\n",
    "    explained_variance = pca.explained_variance_ratio_ * 100\n",
    "    fig.add_annotation(\n",
    "        text=f\"Explained Variance:<br>PC1: {explained_variance[0]:.2f}%<br>PC2: {explained_variance[1]:.2f}%\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=1.16, y=0.5,\n",
    "        showarrow=False,\n",
    "        align=\"left\",\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_morbidities_3d():\n",
    "    \"\"\"\n",
    "    Perform PCA on the morbidities dataset for dimensionality reduction and visualize the top 3 components in 3D.\n",
    "    \"\"\"\n",
    "    # Pivot the morbidities dataset to create a matrix with states as rows and diseases as columns\n",
    "    morbidities_pivot = morbilidad_df.pivot_table(\n",
    "        index='state', columns='sickness', values='value', aggfunc='sum', fill_value=0\n",
    "    )\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(morbidities_pivot)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_results = pca.fit_transform(scaled_data)\n",
    "\n",
    "    # Add PCA components back to the DataFrame\n",
    "    pca_df = pd.DataFrame(\n",
    "        pca_results,\n",
    "        index=morbidities_pivot.index,\n",
    "        columns=['PCA1', 'PCA2', 'PCA3']\n",
    "    )\n",
    "\n",
    "    # Create a numeric column for coloring\n",
    "    pca_df['State_Index'] = pd.factorize(pca_df.index)[0]\n",
    "    \n",
    "    # Explained variance for annotations\n",
    "    explained_variance = pca.explained_variance_ratio_ * 100\n",
    "\n",
    "    # Create a 3D scatter plot for PCA results\n",
    "    fig = px.scatter_3d(\n",
    "        pca_df,\n",
    "        x='PCA1',\n",
    "        y='PCA2',\n",
    "        z='PCA3',\n",
    "        title=\"PCA on Morbidities Dataset by State\",\n",
    "        color='State_Index', \n",
    "        text=pca_df.index,\n",
    "        labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2', 'PCA3': 'Principal Component 3'},\n",
    "        template=\"seaborn\",\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "\n",
    "    # Change font size for annotations\n",
    "    fig.update_traces(textfont=dict(size=8))\n",
    "    \n",
    "    # Add explained variance annotation in the title\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                title=dict(\n",
    "                    text=f\"PC1 ({explained_variance[0]:.2f}%)\",\n",
    "                    font=dict(size=10, style='italic')\n",
    "                ),\n",
    "                tickfont=dict(size=10)\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=dict(\n",
    "                    text=f\"PC2 ({explained_variance[1]:.2f}%)\",\n",
    "                    font=dict(size=10, style='italic')\n",
    "                ),\n",
    "                tickfont=dict(size=10)\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                title=dict(\n",
    "                    text=f\"PC3 ({explained_variance[2]:.2f}%)\",\n",
    "                    font=dict(size=10, style='italic')\n",
    "                ),\n",
    "                tickfont=dict(size=10)\n",
    "            ),\n",
    "        ),\n",
    "        coloraxis_showscale=False#,\n",
    "       #margin=dict(l=20, r=20, t=40, b=20)  # Adjust the margins as needed\n",
    "    )\n",
    "     \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.rotator import Rotator\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "\n",
    "def factor_analysis_covid():\n",
    "    \"\"\"\n",
    "    Perform Factor Analysis on the COVID dataset using the factor_analyzer library with Varimax rotation.\n",
    "    \"\"\"\n",
    "    # Select features for Factor Analysis\n",
    "    features = ['DIABETES', 'HIPERTENSION', 'OBESIDAD', 'ASMA', 'EPOC', \n",
    "                'INMUSUPR', 'CARDIOVASCULAR', 'RENAL_CRONICA', 'TABAQUISMO']\n",
    "    covid_features = covid_df[features].fillna(0)\n",
    "\n",
    "    # Standardize the data\n",
    "    standardized_data = zscore(covid_features)\n",
    "\n",
    "    # Apply Factor Analysis\n",
    "    n_factors = 2  # Number of factors to extract\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation=None, method='principal')\n",
    "    fa.fit(standardized_data)\n",
    "\n",
    "    # Extract unrotated factor loadings\n",
    "    loadings = fa.loadings_\n",
    "\n",
    "    # Apply Varimax Rotation\n",
    "    rotator = Rotator(method='varimax')\n",
    "    rotated_loadings = rotator.fit_transform(loadings)\n",
    "\n",
    "    # Create a DataFrame for rotated loadings\n",
    "    loading_df = pd.DataFrame(\n",
    "        rotated_loadings,\n",
    "        index=features,  # Features as rows\n",
    "        columns=[f\"Factor {i+1}\" for i in range(n_factors)]  # Factors as columns\n",
    "    )\n",
    "\n",
    "    # Create heatmap for rotated loadings\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=loading_df.values,\n",
    "        x=loading_df.columns.tolist(),  # Factors\n",
    "        y=loading_df.index.tolist(),   # Features\n",
    "        annotation_text=np.round(loading_df.values, 2),  # Rounded values for annotations\n",
    "        colorscale='Blues',\n",
    "        showscale=False\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Rotated Factor Loadings (Varimax) for COVID Dataset\",\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"Features\",\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_analysis_dengue():\n",
    "    \"\"\"\n",
    "    Perform Factor Analysis on the Dengue dataset using the factor_analyzer library with Varimax rotation.\n",
    "    \"\"\"\n",
    "    # Select features for Factor Analysis\n",
    "    features = ['DIABETES', 'HIPERTENSION', 'ENFERMEDAD_ULC_PEPTICA', \n",
    "                'ENFERMEDAD_RENAL', 'INMUNOSUPR', 'CIRROSIS_HEPATICA']\n",
    "    dengue_features = dengue_df[features].fillna(0)\n",
    "\n",
    "    # Standardize the data\n",
    "    standardized_data = zscore(dengue_features)\n",
    "\n",
    "    # Apply Factor Analysis\n",
    "    n_factors = 2  # Number of factors to extract\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation=None, method='principal')\n",
    "    fa.fit(standardized_data)\n",
    "\n",
    "    # Extract unrotated factor loadings\n",
    "    loadings = fa.loadings_\n",
    "\n",
    "    # Apply Varimax Rotation\n",
    "    rotator = Rotator(method='varimax')\n",
    "    rotated_loadings = rotator.fit_transform(loadings)\n",
    "\n",
    "    # Create a DataFrame for rotated loadings\n",
    "    loading_df = pd.DataFrame(\n",
    "        rotated_loadings,\n",
    "        index=features,  # Features as rows\n",
    "        columns=[f\"Factor {i+1}\" for i in range(n_factors)]  # Factors as columns\n",
    "    )\n",
    "\n",
    "    # Create heatmap for rotated loadings\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=loading_df.values,\n",
    "        x=loading_df.columns.tolist(),  # Factors\n",
    "        y=loading_df.index.tolist(),   # Features\n",
    "        annotation_text=np.round(loading_df.values, 2),  # Rounded values for annotations\n",
    "        colorscale='Blues',\n",
    "        showscale=False\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Rotated Factor Loadings (Varimax) for Dengue Dataset\",\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"Features\",\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_analysis_febriles():\n",
    "    \"\"\"\n",
    "    Perform Factor Analysis on the Febriles dataset using the factor_analyzer library with Varimax rotation.\n",
    "    \"\"\"\n",
    "    # Select features for Factor Analysis\n",
    "    features = ['COMPLICACIONES', 'DEFUNCION', 'VACUNACION', 'DIAGNOSTICO']\n",
    "    febriles_features = febriles_df[features].fillna(0)\n",
    "\n",
    "    # Standardize the data\n",
    "    standardized_data = zscore(febriles_features)\n",
    "\n",
    "    # Apply Factor Analysis\n",
    "    n_factors = 2  # Number of factors to extract\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation=None, method='principal')\n",
    "    fa.fit(standardized_data)\n",
    "\n",
    "    # Extract unrotated factor loadings\n",
    "    loadings = fa.loadings_\n",
    "\n",
    "    # Apply Varimax Rotation\n",
    "    rotator = Rotator(method='varimax')\n",
    "    rotated_loadings = rotator.fit_transform(loadings)\n",
    "\n",
    "    # Create a DataFrame for rotated loadings\n",
    "    loading_df = pd.DataFrame(\n",
    "        rotated_loadings,\n",
    "        index=features,  # Features as rows\n",
    "        columns=[f\"Factor {i+1}\" for i in range(n_factors)]  # Factors as columns\n",
    "    )\n",
    "\n",
    "    # Define a custom colormap from the middle to the upper end of `Blues`\n",
    "    blues_colormap = [[0.0, 'rgb(190, 220, 240)'],  # Lighter blue\n",
    "                      [0.5, 'rgb(100, 150, 200)'],  # Mid blue\n",
    "                      [1.0, 'rgb(0, 70, 150)']]    # Darker blue\n",
    "    \n",
    "    # Create heatmap for rotated loadings\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=loading_df.values,\n",
    "        x=loading_df.columns.tolist(),  # Factors\n",
    "        y=loading_df.index.tolist(),   # Features\n",
    "        annotation_text=np.round(loading_df.values, 2),  # Rounded values for annotations\n",
    "        colorscale=blues_colormap,\n",
    "        showscale=True\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Rotated Factor Loadings (Varimax) for Febriles Dataset\",\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"Features\",\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def logistic_regression_tipo_paciente():\n",
    "    \"\"\"\n",
    "    Logistic Regression for predicting TIPO_PACIENTE (Ambulatorio vs Hospitalized)\n",
    "    using comorbidities in the COVID dataset.\n",
    "    \"\"\"\n",
    "    # Filter the dataset for necessary columns and valid TIPO_PACIENTE values\n",
    "    covid_filtered = covid_df[covid_df['TIPO_PACIENTE'].isin([1, 2])].copy()\n",
    "    features = ['DIABETES', 'HIPERTENSION', 'OBESIDAD']\n",
    "    target = 'TIPO_PACIENTE'\n",
    "\n",
    "    # Handle missing values (assume NA = 2 for \"No\" in this case)\n",
    "    covid_filtered[features] = covid_filtered[features].fillna(2)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = covid_filtered[features]\n",
    "    y = covid_filtered[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Initialize Logistic Regression model\n",
    "    model = LogisticRegression(random_state=69, max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=['Ambulatorio', 'Hospitalizado'])\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Feature Importance (Coefficients)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Coefficient': np.round(model.coef_[0], 3)\n",
    "    }).sort_values(by='Coefficient', ascending=False)\n",
    "    \n",
    "    return model, acc, report, cm, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "def random_forest_clasificacion_final():\n",
    "    \"\"\"\n",
    "    Random Forest for predicting CLASIFICACION_FINAL (e.g., positive, negative, suspected)\n",
    "    using comorbidities in the COVID dataset.\n",
    "    \"\"\"\n",
    "    # Filter the dataset for necessary columns\n",
    "    covid_filtered = covid_df[covid_df['CLASIFICACION_FINAL'].isin(range(1, 8))].copy()\n",
    "    features = ['DIABETES', 'HIPERTENSION', 'OBESIDAD', 'ASMA', 'EPOC', 'INMUSUPR']\n",
    "    target = 'CLASIFICACION_FINAL'\n",
    "\n",
    "    # Handle missing values (assume NA = 2 for \"No\" in this case)\n",
    "    covid_filtered[features] = covid_filtered[features].fillna(2)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = covid_filtered[features]\n",
    "    y = covid_filtered[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69, stratify=y)\n",
    "\n",
    "    # Initialize Random Forest model\n",
    "    model = RandomForestClassifier(random_state=42, class_weight=None, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\n",
    "        'Confirmed by Association', 'Confirmed by Decease', 'Confirmed by Laboratory',\n",
    "        'Invalid', 'Not Applicable', 'Suspected', 'Negative'\n",
    "    ], zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return model, acc, report, cm, feature_importance, X_test, y_test, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def precision_recall_curve_rf(y_test, y_pred_proba, n_classes=7):\n",
    "    \"\"\"\n",
    "    Generate a Precision-Recall curve for Random Forest predictions.\n",
    "    Handles cases where no positive samples exist for a class.\n",
    "    \"\"\"\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        # Check if the class has any positive samples in y_test\n",
    "        if (y_test == i).sum() == 0:\n",
    "            continue  # Skip classes with no positive samples\n",
    "\n",
    "        # Compute precision-recall curve\n",
    "        precision[i], recall[i], _ = precision_recall_curve(\n",
    "            (y_test == i).astype(int), y_pred_proba[:, i]\n",
    "        )\n",
    "\n",
    "        # Add curve to the figure\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=recall[i], y=precision[i],\n",
    "            mode='lines',\n",
    "            name=f'Class {i}'\n",
    "        ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Precision-Recall Curve (Random Forest)',\n",
    "        xaxis_title='Recall',\n",
    "        yaxis_title='Precision',\n",
    "        template='seaborn'\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weighted_metrics(report, accuracy):\n",
    "    \"\"\"\n",
    "    Extract accuracy, weighted precision, recall, and F1-score from a classification report.\n",
    "    \"\"\"\n",
    "    report_lines = report.split(\"\\n\")\n",
    "    weighted_line = report_lines[-2].split()  # Weighted Avg is usually the second-to-last line\n",
    "\n",
    "    metrics = {\n",
    "        \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
    "        \"Value\": [accuracy, float(weighted_line[-4]), float(weighted_line[-3]), float(weighted_line[-2])]\n",
    "    }\n",
    "    return pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef gradient_boosting_resultado_pcr():\\n\\n    #Gradient Boosting for predicting RESULTADO_PCR (positive/negative/other)\\n    #using demographic and temporal features in the Dengue dataset.\\n\\n    # Filter Dengue dataset for necessary columns\\n    dengue_filtered = dengue_df[dengue_df['RESULTADO_PCR'].isin([1, 2, 3, 4, 5])].copy()\\n    features = ['EDAD_ANOS', 'DIABETES', 'HIPERTENSION', 'HEMORRAGICOS', 'FECHA_SIGN_SINTOMAS']\\n    target = 'RESULTADO_PCR'\\n\\n    # Preprocess data\\n    dengue_filtered['FECHA_SIGN_SINTOMAS'] = (\\n        (dengue_filtered['FECHA_SIGN_SINTOMAS'] - dengue_filtered['FECHA_SIGN_SINTOMAS'].min()).dt.days\\n    )  # Convert dates to numerical days\\n    dengue_filtered[features] = dengue_filtered[features].fillna(0)  # Fill missing values\\n\\n    # Split data into training and testing sets\\n    X = dengue_filtered[features]\\n    y = dengue_filtered[target]\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\\n\\n    # Initialize Gradient Boosting model\\n    model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1)\\n    model.fit(X_train, y_train)\\n\\n    # Predictions\\n    y_pred = model.predict(X_test)\\n\\n    # Metrics\\n    acc = accuracy_score(y_test, y_pred)\\n    report = classification_report(y_test, y_pred, target_names=[\\n        'Positive', 'Negative', 'Invalid', 'Suspected', 'Other'\\n    ])\\n    cm = confusion_matrix(y_test, y_pred)\\n\\n    # Feature Importance\\n    feature_importance = pd.DataFrame({\\n        'Feature': features,\\n        'Importance': model.feature_importances_\\n    }).sort_values(by='Importance', ascending=False)\\n\\n    return model, acc, report, cm, feature_importance\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\"\"\"\n",
    "def gradient_boosting_resultado_pcr():\n",
    "\n",
    "    #Gradient Boosting for predicting RESULTADO_PCR (positive/negative/other)\n",
    "    #using demographic and temporal features in the Dengue dataset.\n",
    "\n",
    "    # Filter Dengue dataset for necessary columns\n",
    "    dengue_filtered = dengue_df[dengue_df['RESULTADO_PCR'].isin([1, 2, 3, 4, 5])].copy()\n",
    "    features = ['EDAD_ANOS', 'DIABETES', 'HIPERTENSION', 'HEMORRAGICOS', 'FECHA_SIGN_SINTOMAS']\n",
    "    target = 'RESULTADO_PCR'\n",
    "\n",
    "    # Preprocess data\n",
    "    dengue_filtered['FECHA_SIGN_SINTOMAS'] = (\n",
    "        (dengue_filtered['FECHA_SIGN_SINTOMAS'] - dengue_filtered['FECHA_SIGN_SINTOMAS'].min()).dt.days\n",
    "    )  # Convert dates to numerical days\n",
    "    dengue_filtered[features] = dengue_filtered[features].fillna(0)  # Fill missing values\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = dengue_filtered[features]\n",
    "    y = dengue_filtered[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Initialize Gradient Boosting model\n",
    "    model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\n",
    "        'Positive', 'Negative', 'Invalid', 'Suspected', 'Other'\n",
    "    ])\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return model, acc, report, cm, feature_importance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef save_gradient_boosting_results():\\n    # Generate results\\n    model, acc, report, cm, feature_importance = gradient_boosting_resultado_pcr()\\n\\n    # Prepare data to save\\n    results = {\\n        \"accuracy\": acc,\\n        \"classification_report\": report,\\n        \"confusion_matrix\": cm.tolist(),\\n        \"feature_importance\": feature_importance.to_dict(orient=\"records\")\\n    }\\n\\n    # Save to JSON\\n    with open(\"assets/gradient_boosting_results.json\", \"w\") as f:\\n        json.dump(results, f, indent=4)\\n\\nsave_gradient_boosting_results()\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def save_gradient_boosting_results():\n",
    "    # Generate results\n",
    "    model, acc, report, cm, feature_importance = gradient_boosting_resultado_pcr()\n",
    "\n",
    "    # Prepare data to save\n",
    "    results = {\n",
    "        \"accuracy\": acc,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"feature_importance\": feature_importance.to_dict(orient=\"records\")\n",
    "    }\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(\"assets/gradient_boosting_results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "save_gradient_boosting_results()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gradient_boosting_results():\n",
    "    # Load JSON file\n",
    "    with open(\"assets/gradient_boosting_results.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Parse results\n",
    "    acc = results[\"accuracy\"]\n",
    "    report = results[\"classification_report\"]\n",
    "    cm = results[\"confusion_matrix\"]\n",
    "    feature_importance = pd.DataFrame(results[\"feature_importance\"])\n",
    "\n",
    "    return acc, report, cm, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "def random_forest_dictamen():\n",
    "    \"\"\"\n",
    "    Random Forest for predicting DICTAMEN using demographic and medical features in the Dengue dataset.\n",
    "    \"\"\"\n",
    "    # Filter Dengue dataset for necessary columns\n",
    "    dengue_filtered = dengue_df[dengue_df['DICTAMEN'].isin([1, 2, 3, 4])].copy()\n",
    "    features = ['EDAD_ANOS', 'ENTIDAD_RES', 'DIABETES', 'HIPERTENSION', 'HEMORRAGICOS']\n",
    "    target = 'DICTAMEN'\n",
    "\n",
    "    # Preprocess data\n",
    "    dengue_filtered[features] = dengue_filtered[features].fillna(0)  # Fill missing values\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = dengue_filtered[features]\n",
    "    y = dengue_filtered[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69, stratify=y)\n",
    "\n",
    "    # Initialize Random Forest model\n",
    "    model = RandomForestClassifier(random_state=42, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)  # Required for ROC curve\n",
    "\n",
    "    # Dynamically set target names and labels based on the unique classes in y\n",
    "    unique_classes = sorted(y.unique())\n",
    "    target_names = [f\"Class {cls}\" for cls in unique_classes]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)  # Use `labels` to match classes exactly\n",
    "\n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return model, acc, report, cm, feature_importance, X_test, y_test, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def roc_curve_rf(y_test, y_pred_proba, n_classes=None):\n",
    "    \"\"\"\n",
    "    Generate an ROC Curve for Random Forest predictions.\n",
    "    Dynamically handles cases where no positive samples exist for a class.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Dynamically determine the number of classes from y_test and y_pred_proba\n",
    "    if n_classes is None:\n",
    "        n_classes = y_pred_proba.shape[1]\n",
    "\n",
    "    # Compute ROC curve and AUC for each class\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        # Check if the class exists in y_test\n",
    "        if (y_test == i).sum() == 0:\n",
    "            continue  # Skip classes with no positive samples\n",
    "\n",
    "        # Compute ROC curve\n",
    "        fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_pred_proba[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Add curve to the figure\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=fpr[i], y=tpr[i],\n",
    "            mode='lines',\n",
    "            line=dict(color=['#006EC1', '#006EC1'][i % 2]), \n",
    "            name=f'Class {i} (AUC = {roc_auc[i]:.2f})'\n",
    "        ))\n",
    "\n",
    "    # Add diagonal reference line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[0, 1],\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', color='#89D1F3'),\n",
    "        name='No Skill'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='ROC Curve (Random Forest)',\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        template='seaborn'\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def qda_classification_dengue():\n",
    "    \"\"\"\n",
    "    Perform QDA classification for DEFUNCION on the Dengue dataset and evaluate the model.\n",
    "    \"\"\"\n",
    "    # Select features and target variable\n",
    "    features = ['EDAD_ANOS', 'DIABETES', 'HIPERTENSION', 'INMUNOSUPR', 'EMBARAZO']\n",
    "    target = 'DEFUNCION'\n",
    "    \n",
    "    # Prepare the data\n",
    "    X = dengue_df[features].fillna(0)\n",
    "    y = dengue_df[target]\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize QDA model\n",
    "    qda_model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "    # Train the model\n",
    "    qda_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = qda_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=['Alive', 'Deceased'])\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Compute pseudo-feature importances for QDA (based on absolute mean differences in the means of the features per class)\n",
    "    class_means = qda_model.means_\n",
    "    importance = np.abs(class_means[0] - class_means[1])  # Differences between class means\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return qda_model, acc, report, cm, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "\n",
    "def qda_dengue_defuncion():\n",
    "    \"\"\"\n",
    "    Apply Quadratic Discriminant Analysis (QDA) to the Dengue dataset for DEFUNCION prediction.\n",
    "    \"\"\"\n",
    "    # Select features and target variable\n",
    "    features = ['EDAD_ANOS', 'DIABETES', 'HIPERTENSION', 'CIRROSIS_HEPATICA', 'INMUNOSUPR']\n",
    "    dengue_filtered = dengue_df.dropna(subset=features + ['DEFUNCION'])\n",
    "    X = dengue_filtered[features]\n",
    "    y = dengue_filtered['DEFUNCION']\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply QDA\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(X_scaled, y)\n",
    "    \n",
    "    # Compute QDA scores\n",
    "    qda_scores = qda.decision_function(X_scaled)\n",
    "    dengue_filtered['QDA1'] = qda_scores if qda_scores.ndim == 1 else qda_scores[:, 0]\n",
    "    \n",
    "    qda_colors = {1: 'Deceased', 2: 'Alive'}\n",
    "    dengue_filtered['DEFUNCION_Label'] = dengue_filtered['DEFUNCION'].map(qda_colors)\n",
    "\n",
    "    # Visualization\n",
    "    fig = px.scatter(\n",
    "        dengue_filtered,\n",
    "        x='QDA1',\n",
    "        y=dengue_filtered.index,\n",
    "        color='DEFUNCION_Label',\n",
    "        title=\"QDA Projection for DEFUNCION in Dengue Dataset\",\n",
    "        labels={'color': 'DEFUNCION', 'QDA1': 'QDA Component 1', 'DEFUNCION_Label': 'DEFUNCION'},\n",
    "        template='seaborn',\n",
    "        color_discrete_map={'Deceased': '#006EC1', 'Alive': '#52BCEC'}\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        #coloraxis_showscale=False,  # Hide color bar\n",
    "        xaxis_title=\"QDA1\",\n",
    "        yaxis_title=\"Index\"\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import json\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_tab = dbc.Tab(\n",
    "    label=\"Exploratory Data Analysis\",\n",
    "    children=[\n",
    "        # COVID-19 Subtitle and Visualizations\n",
    "        html.H4(\"COVID-19 Dataset\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents exploratory data analysis (EDA) for the COVID-19 dataset, \"\n",
    "            \"covering demographic, temporal, geospatial, and medical insights.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),  \n",
    "\n",
    "        # Row for Age and Gender Distribution, and Cases Over Time\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='age-gender-distribution', figure=covid_age_gender_distribution(), \n",
    "                              style={'height': '400px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='cases-over-time', figure=covid_cases_over_time(), \n",
    "                              style={'height': '400px'}), width=6),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '15px'}), \n",
    "\n",
    "        # Row for Geospatial Distribution of Cases\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='geospatial-cases', figure=covid_cases_geospatial(), \n",
    "                              style={'height': '800px', 'width': '100%'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '30px'}),\n",
    "\n",
    "        # Row for Comorbidity Heatmap and Symptoms-to-Admission Interval\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='comorbidity-heatmap', figure=covid_comorbidity_heatmap(), \n",
    "                              style={'height': '700px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='symptoms-to-admission', figure=covid_symptoms_to_admission(), \n",
    "                              style={'height': '500px'}), width=6),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '30px'}),\n",
    "        \n",
    "        # Dengue Subtitle\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Dengue Dataset\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents exploratory data analysis (EDA) for the Dengue dataset, \"\n",
    "            \"covering demographic, temporal, geospatial, and medical insights.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "\n",
    "        # Dengue Visualizations\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='age-gender-distribution-dengue', figure=dengue_age_gender_distribution(), \n",
    "                              style={'height': '400px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='cases-over-time-dengue', figure=dengue_cases_over_time(), \n",
    "                              style={'height': '400px'}), width=6),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '30px'}),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='hemorrhagic-cases-dengue', figure=dengue_hemorrhagic_cases_pie(), \n",
    "                              style={'height': '400px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='comorbidity-heatmap-dengue', figure=dengue_comorbidity_heatmap(),\n",
    "                              style={'height': '400px'}), width=6),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '30px'}),\n",
    "        \n",
    "        \n",
    "        # Febriles Subtitle\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Diseases with Fever and Exanthema Dataset\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents exploratory data analysis (EDA) for the Diseases with Fever and Exanthema dataset, \"\n",
    "            \"covering demographic, categorical, and geospatial insights.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "\n",
    "        # Febriles Visualizations\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='febriles-strip', figure=febriles_strip_plot(), \n",
    "                              style={'height': '500px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='febriles-parallel-categories', figure=febriles_parallel_categories(), \n",
    "                            style={'height': '500px'}), width=6),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '15px'}),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='febriles-geospatial', figure=febriles_geospatial_distribution(), \n",
    "                            style={'height': '800px', 'width': '100%'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '30px'}),\n",
    "\n",
    "\n",
    "        # Morbilidad Subtitle\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Morbilidad Dataset\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents exploratory data analysis (EDA) for the Morbilidad dataset, \"\n",
    "            \"highlighting trends, proportions, and geospatial distributions of diseases.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "\n",
    "        # Morbilidad Visualizations\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='morbilidad-top-diseases', figure=morbilidad_top_diseases_over_time(), \n",
    "                            style={'height': '500px'}), width=12),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '30px'}),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='morbilidad-treemap', figure=morbilidad_treemap(), \n",
    "                            style={'height': '800px'}), width=11),\n",
    "        ], className=\"mb-4\", style={'margin-bottom': '15px'}),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='morbilidad-geospatial', figure=morbilidad_geospatial_distribution(), \n",
    "                            style={'height': '800px'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '30px'}),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate results\n",
    "covid_dengue_manova_summary = manova_covid_dengue()\n",
    "covid_single_manova_summary = manova_covid_single()\n",
    "\n",
    "# Add tables and plots to the dashboard\n",
    "stat_tests_tab = dbc.Tab(\n",
    "    label=\"Statistical Tests\",\n",
    "    children=[\n",
    "        # ANOVA Section\n",
    "        html.H4(\"Analysis of Variance (ANOVA)\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents ANOVA results analyzing differences in age across the datasets (COVID, Dengue, Febriles).\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='anova-age-datasets', figure=anova_age_across_datasets(), \n",
    "                              style={'height': '500px'}), width=11),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '30px'}),\n",
    "\n",
    "        # Multiple Datasets MANOVA Section\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Multivariate Analysis of Variance (MANOVA)\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P([\n",
    "            \"This section presents MANOVA results for analyzing differences in comorbidities \",\n",
    "            \"(Diabetes, Hypertension, and Pregnancy) between COVID and Dengue datasets.\",\n",
    "            html.Br(),\n",
    "            \"This section also presents MANOVA results for analyzing differences in comorbidities \",\n",
    "            \"(Diabetes, Hypertension, Asthma, EPOC, and Obesity) between ambulatory and hospitalized patients in the COVID dataset.\",\n",
    "        ], style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H5(\"Results: COVID vs. Dengue\", style={'text-align': 'center', 'margin-bottom': '20px'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='manova-covid-dengue-summary',\n",
    "                    columns=[{\"name\": col, \"id\": col} for col in covid_dengue_manova_summary.columns],\n",
    "                    data=covid_dengue_manova_summary.to_dict('records'),\n",
    "                    style_table={'overflowX': 'auto'},\n",
    "                    style_cell={'textAlign': 'center', 'padding': '5px'},\n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "                    style_as_list_view=True,\n",
    "                )\n",
    "            ]), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '40px'}),\n",
    "\n",
    "        # Single Dataset MANOVA Section\n",
    "        html.Br(),\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H5(\"Results: Ambulatory vs. Hospitalized COVID Patients\", style={'text-align': 'center', 'margin-bottom': '20px'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='manova-covid-single-summary',\n",
    "                    columns=[{\"name\": col, \"id\": col} for col in covid_single_manova_summary.columns],\n",
    "                    data=covid_single_manova_summary.to_dict('records'),\n",
    "                    style_table={'overflowX': 'auto'},\n",
    "                    style_cell={'textAlign': 'center', 'padding': '5px'},\n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "                    style_as_list_view=True,\n",
    "                )\n",
    "            ]), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '50px'}),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_tab = dbc.Tab(\n",
    "    label=\"Clustering\",\n",
    "    children=[\n",
    "        # Agglomerative and Time Series Clustering Section\n",
    "        html.H4(\"Agglomerative and Time Series Clustering\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section presents clustering analyses, including K-Means and K-Prototypes for grouping based on \"\n",
    "            \"numerical and mixed data, as well as hierarchical clustering and time-series clustering for uncovering \"\n",
    "            \"temporal patterns and structural groupings.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='kmeans-dengue', figure=kmeans_dengue_clustering(), style={'height': '500px'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='kprototypes-febriles', figure=kprototypes_febriles(), style={'height': '500px'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '40px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div(hierarchical_clustering_covid(), style={'height': '500px'}), width=5),\n",
    "            dbc.Col(dcc.Graph(id='time-series-clustering-means', figure=time_series_clustering_morbidities(), style={'height': '500px'}), width=6),\n",
    "        ], className=\"justify-content-center mb-4\", style={'margin-bottom': '40px'}),\n",
    "\n",
    "        # PCA Section\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px', 'margin-top': '20px'}),\n",
    "        html.H4(\"Principal Component Analysis (PCA)\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"Principal Component Analysis is used for dimensionality reduction, allowing us to represent complex datasets \"\n",
    "            \"in a simplified form by extracting the components that explain the most variance in the data. The 2D and 3D PCA \"\n",
    "            \"plots below show the distribution of states and their disease profiles based on their principal components.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='pca-covid', figure=pca_covid(), style={'height': '500px'}), width=10),\n",
    "        ], className=\"justify-content-center mb-4\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='pca-morbidities-3d', figure=pca_morbidities_3d(), style={'height': '700px'}), width=12),\n",
    "        ], className=\"justify-content-center mb-4\"),\n",
    "\n",
    "        # Factor Analysis Section\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Factor Analysis (FA)\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"Factor Analysis is a statistical method used to identify latent factors that explain the variability in a dataset. \"\n",
    "            \"By reducing the dimensionality of the data, FA helps uncover patterns and groupings of related variables. Below, \"\n",
    "            \"we explore the relationships between comorbidities in the COVID, Dengue, and Febriles datasets.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='fa-covid', figure=factor_analysis_covid(), style={'height': '500px'}), width=6),\n",
    "            dbc.Col(dcc.Graph(id='fa-dengue', figure=factor_analysis_dengue(), style={'height': '500px'}), width=6),\n",
    "        ], className=\"mb-4\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='fa-febriles', figure=factor_analysis_febriles(), style={'height': '500px'}), width=6),\n",
    "        ], className=\"justify-content-center mb-4\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate results\n",
    "logistic_model, logistic_acc, logistic_report, logistic_cm, logistic_feature_importance = logistic_regression_tipo_paciente()\n",
    "rf_model, rf_acc, rf_report, rf_cm, rf_feature_importance, X_test_rf, y_test_rf, y_pred_proba_rf = random_forest_clasificacion_final()\n",
    "rf_precision_recall_curve = precision_recall_curve_rf(y_test_rf, y_pred_proba_rf, n_classes=7)\n",
    "\n",
    "rf_d_model, rf_d_acc, rf_d_report, rf_d_cm, rf_d_feature_importance, X_test_rf_d, y_test_rf_d, y_pred_proba_rf_d = random_forest_dictamen()\n",
    "qda_model, qda_acc, qda_report, qda_cm, qda_feature_importance = qda_classification_dengue()\n",
    "gb_acc, gb_report, gb_cm, gb_feature_importance = load_gradient_boosting_results()\n",
    "\n",
    "\n",
    "# Extract weighted metrics for each model\n",
    "logistic_metrics_df = extract_weighted_metrics(logistic_report, logistic_acc).round(3)\n",
    "rf_metrics_df = extract_weighted_metrics(rf_report, rf_acc).round(3)\n",
    "\n",
    "rf_d_metrics_df = extract_weighted_metrics(rf_d_report, rf_d_acc).round(3)\n",
    "qda_metrics_df = extract_weighted_metrics(qda_report, qda_acc).round(3)\n",
    "gb_metrics_df = extract_weighted_metrics(gb_report, gb_acc).round(3)\n",
    "\n",
    "classification_tab = dbc.Tab(\n",
    "    label=\"Classification\",\n",
    "    children=[\n",
    "        # COVID Section\n",
    "        html.H4(\"COVID-19 Classification Results\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section showcases the results of classification models applied to the COVID-19 dataset. \"\n",
    "            \"We include Logistic Regression and Random Forest methods to predict patient types and COVID classifications.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "\n",
    "        # Logistic Regression Results\n",
    "        html.H5(\"Logistic Regression for TIPO_PACIENTE\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        dbc.Row([\n",
    "            # Metrics Table\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Metrics Summary\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='logistic-metrics-table',\n",
    "                    columns=[{'name': col, 'id': col} for col in logistic_metrics_df.columns],\n",
    "                    data=logistic_metrics_df.to_dict('records'),\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ], style={'align-items': 'center', 'justify-content': 'center'}), width=5),\n",
    "        \n",
    "            # Feature Importance\n",
    "            dbc.Col(dcc.Graph(\n",
    "                id='logistic-feature-importance',\n",
    "                figure=px.bar(\n",
    "                    logistic_feature_importance, \n",
    "                    x='Feature', y='Coefficient',\n",
    "                    title=\"Feature Importance (Logistic Regression)\",\n",
    "                    template='seaborn',\n",
    "                    color='Feature',\n",
    "                    color_discrete_sequence=['#006EC1', '#009EE5', '#89D1F3']\n",
    "                )\n",
    "            ), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'display': 'flex', 'align-items': 'center'}),\n",
    "\n",
    "        # Confusion Matrix\n",
    "        html.Br(),\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Confusion Matrix\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='logistic-confusion-matrix',\n",
    "                    columns=[\n",
    "                        {'name': 'Predicted Ambulatorio', 'id': 'Ambulatorio'},\n",
    "                        {'name': 'Predicted Hospitalizado', 'id': 'Hospitalizado'}\n",
    "                    ],\n",
    "                    data=[\n",
    "                        {\"Ambulatorio\": logistic_cm[0][0], \"Hospitalizado\": logistic_cm[0][1]},\n",
    "                        {\"Ambulatorio\": logistic_cm[1][0], \"Hospitalizado\": logistic_cm[1][1]}\n",
    "                    ],\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ]), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'margin-bottom': '100px'}),\n",
    "\n",
    "        # Random Forest Results\n",
    "        html.H5(\"Random Forest for CLASIFICACION_FINAL\", style={'text-align': 'center', 'margin-top': '100px'}),\n",
    "        dbc.Row([\n",
    "            # Metrics Table\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Metrics Summary\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='rf-metrics-table',\n",
    "                    columns=[{'name': col, 'id': col} for col in rf_metrics_df.columns],\n",
    "                    data=rf_metrics_df.to_dict('records'),\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ], style={'align-items': 'center', 'justify-content': 'center'}), width=5),\n",
    "            \n",
    "            # Precision-Recall Curve\n",
    "            dbc.Col(dcc.Graph(\n",
    "                id='rf-precision-recall',\n",
    "                figure=rf_precision_recall_curve, \n",
    "                style={'height': '400px'}\n",
    "            ), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'display': 'flex', 'align-items': 'center'}),\n",
    "\n",
    "        # Confusion Matrix\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Confusion Matrix\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='rf-confusion-matrix',\n",
    "                    columns=[\n",
    "                        {'name': f'Predicted {cls}', 'id': f'Class {i}'}\n",
    "                        for i, cls in enumerate([\n",
    "                            'Association', 'Decease', 'Laboratory', 'Invalid', 'Not Applicable', 'Suspected', 'Negative'\n",
    "                        ])\n",
    "                    ],\n",
    "                    data=[\n",
    "                        {f'Class {i}': row[i] for i in range(len(row))}\n",
    "                        for row in rf_cm  # Confusion matrix\n",
    "                    ],\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ]), width=12),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'margin-bottom': '150px'}),\n",
    "        \n",
    "        \n",
    "        # Dengue Section\n",
    "        html.Br(style={'margin-bottom': '200px'}),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        html.H4(\"Dengue Classification Results\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        html.P(\n",
    "            \"This section showcases the results of classification models applied to the Dengue dataset. \"\n",
    "            \"We include Gradient Boosting, Random Forest, and QDA methods to predict various outcomes, such as PCR results, diagnosis, and mortality.\",\n",
    "            style={'text-align': 'center', 'margin-bottom': '40px'}\n",
    "        ),\n",
    "        html.Hr(style={'border': '1px solid #ccc', 'margin-bottom': '30px'}),\n",
    "        \n",
    "        \n",
    "        # Gradient Boosting Results\n",
    "        html.H5(\"Gradient Boosting for RESULTADO_PCR\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        dbc.Row([\n",
    "            # Metrics Table\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Metrics Summary\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='gb-metrics-table',\n",
    "                    columns=[{'name': col, 'id': col} for col in gb_metrics_df.columns],\n",
    "                    data=gb_metrics_df.to_dict('records'),\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ], style={'align-items': 'center', 'justify-content': 'center'}), width=5),\n",
    "\n",
    "            # Feature Importance\n",
    "            dbc.Col(dcc.Graph(\n",
    "                id='gb-feature-importance',\n",
    "                figure=px.bar(\n",
    "                    gb_feature_importance,\n",
    "                    x='Feature', y='Importance',\n",
    "                    title=\"Feature Importance (Gradient Boosting)\",\n",
    "                    template='seaborn',\n",
    "                    color='Feature',\n",
    "                    color_discrete_sequence=['#006EC1', '#009EE5', '#52BCEC', '#89D1F3', '#B5E5F9']\n",
    "                )\n",
    "            ), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'display': 'flex', 'align-items': 'center', 'margin-bottom': '30px'}),       \n",
    "        \n",
    "        \n",
    "        # Random Forest Results\n",
    "        html.Br(style={'margin-bottom': '100px'}),\n",
    "        html.H5(\"Random Forest for DICTAMEN\", style={'text-align': 'center', 'margin-top': '20px'}),\n",
    "        dbc.Row([\n",
    "            # Metrics Table\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Metrics Summary\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='rf-d-metrics-table',\n",
    "                    columns=[{'name': col, 'id': col} for col in rf_d_metrics_df.columns],\n",
    "                    data=rf_d_metrics_df.to_dict('records'),\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ], style={'align-items': 'center', 'justify-content': 'center'}), width=5),\n",
    "\n",
    "            # ROC Curve\n",
    "            dbc.Col(dcc.Graph(\n",
    "                id='rf-d-roc-curve',\n",
    "                figure=roc_curve_rf(y_test_rf_d, y_pred_proba_rf_d),\n",
    "                style={'height': '400px'}\n",
    "            ), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'display': 'flex', 'align-items': 'center'}),\n",
    "\n",
    "        # Confusion Matrix\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Confusion Matrix\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='rf-d-confusion-matrix',\n",
    "                    columns=[\n",
    "                        {'name': f'Predicted {cls}', 'id': f'Class {i}'}\n",
    "                        for i, cls in enumerate(['Dengue', 'Chikungunya', 'Negative'])  # Limit to three columns\n",
    "                    ],\n",
    "                    data=[\n",
    "                        {f'Class {i}': row[i] if i < len(row) else None for i in range(3)}  # Ensure only 3 columns are passed\n",
    "                        for row in rf_d_cm\n",
    "                    ],\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ]), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'margin-bottom': '100px'}),\n",
    "\n",
    "\n",
    "        # QDA Results\n",
    "        html.H5(\"Quadratic Discriminant Analysis (QDA) for DEFUNCION\", style={'text-align': 'center', 'margin-top': '100px'}),\n",
    "        dbc.Row([\n",
    "            # Metrics Table\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Metrics Summary\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='qda-metrics-table',\n",
    "                    columns=[{'name': col, 'id': col} for col in qda_metrics_df.columns],\n",
    "                    data=qda_metrics_df.to_dict('records'),\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ], style={'align-items': 'center', 'justify-content': 'center'}), width=5),\n",
    "\n",
    "            # QDA Projection Plot\n",
    "            dbc.Col(dcc.Graph(\n",
    "                id='qda-projection',\n",
    "                figure=qda_dengue_defuncion(),\n",
    "                style={'height': '400px'}\n",
    "            ), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'display': 'flex', 'align-items': 'center'}),\n",
    "\n",
    "        # Confusion Matrix\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H6(\"Confusion Matrix\", style={'text-align': 'center'}),\n",
    "                dash_table.DataTable(\n",
    "                    id='qda-confusion-matrix',\n",
    "                    columns=[\n",
    "                        {'name': 'Predicted Alive', 'id': 'Alive'},\n",
    "                        {'name': 'Predicted Deceased', 'id': 'Deceased'}\n",
    "                    ],\n",
    "                    data=[\n",
    "                        {\"Alive\": qda_cm[0][0], \"Deceased\": qda_cm[0][1]},\n",
    "                        {\"Alive\": qda_cm[1][0], \"Deceased\": qda_cm[1][1]}\n",
    "                    ],\n",
    "                    style_cell={'textAlign': 'center'},\n",
    "                    style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},\n",
    "                    style_as_list_view=True\n",
    "                )\n",
    "            ]), width=6),\n",
    "        ], className=\"mb-4 justify-content-center\", style={'margin-bottom': '100px'})\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import dash_bootstrap_components as dbc\n",
    "import os\n",
    "\n",
    "# Create the app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.title = \"Project: Analysis of Morbidity Patterns and Use of Services in the IMSS\"\n",
    "\n",
    "# Combine tabs into layout\n",
    "app.layout = dbc.Container(\n",
    "    [\n",
    "        dbc.NavbarSimple(\n",
    "            brand=\"Project: Analysis of Morbidity Patterns and Use of Services in the IMSS\",\n",
    "            brand_href=\"#\",\n",
    "            color=\"primary\",\n",
    "            dark=True,\n",
    "        ),\n",
    "        dbc.Tabs([eda_tab, stat_tests_tab, clustering_tab, classification_tab]),\n",
    "        html.Footer(\n",
    "            [\n",
    "                html.Hr(),\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.P(\n",
    "                            \"Sources of Information:\",\n",
    "                            style={\"fontWeight\": \"bold\", \"fontSize\": \"16px\", \"marginBottom\": \"5px\"}\n",
    "                        ),\n",
    "                        html.P(\n",
    "                            [\n",
    "                                \"1. Dirección General de Epidemiología: \",\n",
    "                                html.A(\"Anuarios Estadísticos de Morbilidad 1984-2023\", href=\"https://epidemiologia.salud.gob.mx/anuario/html/morbilidad_grupo.html\", target=\"_blank\"),\n",
    "                            ],\n",
    "                            style={\"fontSize\": \"14px\", \"marginBottom\": \"10px\"}\n",
    "                        ),\n",
    "                        html.P(\n",
    "                            [\n",
    "                                \"2. Gobierno de México: \",\n",
    "                                html.A(\"Datos Abiertos\", href=\"https://www.gob.mx/salud/documentos/datos-abiertos-152127\", target=\"_blank\"),\n",
    "                            ],\n",
    "                            style={\"fontSize\": \"14px\", \"marginBottom\": \"10px\"}\n",
    "                        ),\n",
    "                        html.P(\n",
    "                            \"Data collected under sentinel surveillance methods as recommended by WHO, ensuring sample representativity through 475 USMER units across Mexico.\",\n",
    "                            style={\"fontSize\": \"14px\", \"marginBottom\": \"10px\"}\n",
    "                        ),\n",
    "                        html.P(\n",
    "                            \"Data is provided under the regulations of the Open Data Decree published in the Official Gazette of the Federation on February 20, 2015.\",\n",
    "                            style={\"fontSize\": \"14px\"}\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={\"textAlign\": \"center\", \"marginTop\": \"20px\"}\n",
    "                ),\n",
    "            ],\n",
    "            style={\"backgroundColor\": \"#f8f9fa\", \"padding\": \"20px\"}\n",
    "        )\n",
    "    ],\n",
    "    fluid=True,\n",
    "    style={\"padding\": \"20px\"}\n",
    ")\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    port = int(os.environ.get(\"PORT\", 8050))\n",
    "    app.run_server(debug=True, host='127.0.0.1', port=port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
